{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "- Prepare data for analysis\n",
    "- Data almost never comes in clean\n",
    "- Diagnose your data for problems\n",
    "\n",
    "### Common data problems\n",
    "- Inconsistent column names\n",
    "- Missing data\n",
    "- Outliers\n",
    "- Duplicate rows\n",
    "- Untidy\n",
    "- Need to process columns\n",
    "- Column types can signal unexpected data values\n",
    "\n",
    "### Unclean data\n",
    "- Column name inconsistencies\n",
    "- Missing data\n",
    "- Country names are in French\n",
    "\n",
    "### Loading and viewing your data\n",
    "\n",
    "Your first task is to load this dataset into a DataFrame and then inspect it using the .head() and .tail() methods. However, you'll find out very quickly that the printed results don't allow you to see everything you need, since there are too many columns. Therefore, you need to look at the data in another way.\n",
    "\n",
    "The .shape and .columns attributes let you see the shape of the DataFrame and obtain a list of its columns. From here, you can see which columns are relevant to the questions you'd like to ask of the data.\n",
    "\n",
    "Get acquainted with the dataset now by exploring it with pandas! This initial exploratory analysis is a crucial first step of data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ITEM_NO  AMC Item Number                         ITEM_DESC  Logic Count  \\\n",
      "0  44207509       L044207509   DRAWER, DELTA VARIO ATLAS 120MM         1335   \n",
      "1  44207668       L044207668          TOILET PAPER, COTTENELLE          445   \n",
      "2  44207958       L044207958          LINER, TRASH CAN, DOM SM          259   \n",
      "3  44208068       L044208068                 BLANKET, YC (G&G)          371   \n",
      "4  44207583       L044207583   FOAMING SOAP, SQUARE M+G 5.4 oz          523   \n",
      "\n",
      "   Seafrigo Count  Discrepancy (cases)  Discrepancy Value  ACTIVE/INACTIVE  \n",
      "0            2235                  900         $25,945.19            False  \n",
      "1             985                  540         $17,813.36            False  \n",
      "2             759                  500         $14,445.00            False  \n",
      "3             811                  440         $94,467.70            False  \n",
      "4             885                  362         $63,712.00            False  \n",
      "       ITEM_NO  AMC Item Number                              ITEM_DESC  \\\n",
      "1339  44207924       L044207924   BASKET, RECT STAINLESS STEEL - LARGE   \n",
      "1340  44207307       L044207307            BLANKET, DELTA HEAVENLY BED   \n",
      "1341  44208035       L044208035                 DELTA ECONOMY KIT 2017   \n",
      "1342  44207439       L044207439                        MARGARITA MIXER   \n",
      "1343  44206947       L044206947                      CUTLERY, PACK 6/1   \n",
      "\n",
      "      Logic Count  Seafrigo Count  Discrepancy (cases)  Discrepancy Value   \\\n",
      "1339          286             276                  -10           ($948.80)   \n",
      "1340           54              37                  -17           ($515.10)   \n",
      "1341          763             740                  -23         ($2,760.00)   \n",
      "1342          206             178                  -28         ($1,411.20)   \n",
      "1343          917             869                  -48         ($1,681.06)   \n",
      "\n",
      "     ACTIVE/INACTIVE  \n",
      "1339           False  \n",
      "1340           False  \n",
      "1341           False  \n",
      "1342           False  \n",
      "1343           False  \n",
      "(1344, 8)\n",
      "Index([u'ITEM_NO', u' AMC Item Number ', u'ITEM_DESC', u'Logic Count',\n",
      "       u'Seafrigo Count', u'Discrepancy (cases)', u' Discrepancy Value ',\n",
      "       u'ACTIVE/INACTIVE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv('sampledata.csv')\n",
    "\n",
    "# Print the head of df\n",
    "print(df.head())\n",
    "\n",
    "# Print the tail of df\n",
    "print(df.tail())\n",
    "\n",
    "# Print the shape of df\n",
    "print(df.shape)\n",
    "\n",
    "# Print the columns of df\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further diagnosis\n",
    "\n",
    "The .info() method provides important information about a DataFrame, such as the number of rows, number of columns, number of non-missing values in each column, and the data type stored in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1344 entries, 0 to 1343\n",
      "Data columns (total 8 columns):\n",
      "ITEM_NO                1344 non-null object\n",
      " AMC Item Number       1344 non-null object\n",
      "ITEM_DESC              1344 non-null object\n",
      "Logic Count            1344 non-null int64\n",
      "Seafrigo Count         1344 non-null int64\n",
      "Discrepancy (cases)    1344 non-null int64\n",
      " Discrepancy Value     1344 non-null object\n",
      "ACTIVE/INACTIVE        1312 non-null object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 84.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print the info of df\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "\n",
    "### Frequency counts\n",
    "- Count the number of unique values in our data\n",
    "\n",
    "### Summary statistics\n",
    "- Numeric columns\n",
    "- Outliers\n",
    " - Considerably higher or lower\n",
    " - Require further investigation\n",
    " \n",
    "### Calculating summary statistics\n",
    "\n",
    "use the .describe() method to calculate summary statistics of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logic Count</th>\n",
       "      <th>Seafrigo Count</th>\n",
       "      <th>Discrepancy (cases)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1344.000000</td>\n",
       "      <td>1344.000000</td>\n",
       "      <td>1344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>102.223214</td>\n",
       "      <td>105.773065</td>\n",
       "      <td>3.549851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>464.179197</td>\n",
       "      <td>469.909194</td>\n",
       "      <td>38.348567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.250000</td>\n",
       "      <td>36.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9077.000000</td>\n",
       "      <td>9077.000000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Logic Count  Seafrigo Count  Discrepancy (cases)\n",
       "count  1344.000000     1344.000000          1344.000000\n",
       "mean    102.223214      105.773065             3.549851\n",
       "std     464.179197      469.909194            38.348567\n",
       "min       0.000000        0.000000           -48.000000\n",
       "25%       0.000000        0.000000             0.000000\n",
       "50%       0.000000        0.000000             0.000000\n",
       "75%      34.250000       36.250000             0.000000\n",
       "max    9077.000000     9077.000000           900.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency counts for categorical data\n",
    "\n",
    ".describe() can only be used on numeric columns. So how can you diagnose data issues when you have categorical data? One way is by using the .value_counts() method, which returns the frequency counts for each unique value in a column!\n",
    "\n",
    "This method also has an optional parameter called dropna which is True by default. What this means is if you have missing data in a column, it will not give a frequency count of them. You want to set the dropna column to False so if there are missing values in a column, it will give you the frequency counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       895\n",
      "5        10\n",
      "2         9\n",
      "1         8\n",
      "6         6\n",
      "17        5\n",
      "9         5\n",
      "39        5\n",
      "7         4\n",
      "8         4\n",
      "4         4\n",
      "37        4\n",
      "3         4\n",
      "30        4\n",
      "19        4\n",
      "53        4\n",
      "54        4\n",
      "24        4\n",
      "61        3\n",
      "151       3\n",
      "51        3\n",
      "52        3\n",
      "140       3\n",
      "72        3\n",
      "62        3\n",
      "286       3\n",
      "125       3\n",
      "46        3\n",
      "76        3\n",
      "82        3\n",
      "       ... \n",
      "396       1\n",
      "112       1\n",
      "111       1\n",
      "398       1\n",
      "107       1\n",
      "106       1\n",
      "103       1\n",
      "102       1\n",
      "131       1\n",
      "137       1\n",
      "163       1\n",
      "138       1\n",
      "360       1\n",
      "362       1\n",
      "156       1\n",
      "155       1\n",
      "154       1\n",
      "153       1\n",
      "152       1\n",
      "365       1\n",
      "150       1\n",
      "149       1\n",
      "148       1\n",
      "371       1\n",
      "144       1\n",
      "143       1\n",
      "142       1\n",
      "2089      1\n",
      "139       1\n",
      "4010      1\n",
      "Name: Logic Count, Length: 270, dtype: int64\n",
      "0       892\n",
      "5        10\n",
      "2         9\n",
      "1         7\n",
      "6         6\n",
      "17        5\n",
      "3         5\n",
      "9         5\n",
      "30        4\n",
      "46        4\n",
      "48        4\n",
      "24        4\n",
      "51        4\n",
      "53        4\n",
      "19        4\n",
      "37        4\n",
      "88        4\n",
      "8         4\n",
      "7         4\n",
      "4         4\n",
      "125       3\n",
      "62        3\n",
      "278       3\n",
      "86        3\n",
      "54        3\n",
      "72        3\n",
      "83        3\n",
      "50        3\n",
      "76        3\n",
      "40        3\n",
      "       ... \n",
      "377       1\n",
      "2484      1\n",
      "425       1\n",
      "420       1\n",
      "413       1\n",
      "411       1\n",
      "407       1\n",
      "398       1\n",
      "396       1\n",
      "395       1\n",
      "387       1\n",
      "383       1\n",
      "381       1\n",
      "378       1\n",
      "2089      1\n",
      "260       1\n",
      "365       1\n",
      "362       1\n",
      "360       1\n",
      "355       1\n",
      "344       1\n",
      "333       1\n",
      "328       1\n",
      "325       1\n",
      "313       1\n",
      "275       1\n",
      "274       1\n",
      "273       1\n",
      "266       1\n",
      "168       1\n",
      "Name: Seafrigo Count, Length: 276, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the value counts for 'Borough'\n",
    "print(df['Logic Count'].value_counts(dropna=False))\n",
    "\n",
    "# Print the value_counts for 'State'\n",
    "print(df['Seafrigo Count'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual exploratory data analysis\n",
    "\n",
    "### Data visualization\n",
    "- Great way to spot outliers and obvious errors\n",
    "- More than just looking for pa!erns\n",
    "- Plan data cleaning steps\n",
    "\n",
    "### Visualizing single variables with histograms\n",
    "\n",
    "The .plot() method allows you to create a plot of each column of a DataFrame. The kind parameter allows you to specify the type of plot to use - kind='hist', for example, plots a histogram.\n",
    "\n",
    "In the IPython Shell, begin by computing summary statistics for the 'Existing Zoning Sqft' column using the .describe() method. You'll notice that there are extremely large differences between the min and max values, and the plot will need to be adjusted accordingly. In such cases, it's good to look at the plot on a log scale. The keyword arguments logx=True or logy=True can be passed in to .plot() depending on which axis you want to rescale.\n",
    "\n",
    "Finally, note that Python will render a plot such that the axis will hold all the information. That is, if you end up with large amounts of whitespace in your plot, it indicates counts or values too small to render."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEICAYAAABMGMOEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa08e780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the histogram\n",
    "df['Logic Count'].plot(kind='hist', rot=70, logx=True, logy=True)\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing multiple variables with boxplots\n",
    "\n",
    "Histograms are great ways of visualizing single variables. To visualize multiple variables, boxplots are useful, especially when one of the variables is categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box plots\n",
    "- Visualize basic summary statistics\n",
    " - Outliers\n",
    " - Min/max\n",
    " - 25th, 50th, 75th percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAFcCAYAAAA0xeJbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm4XVV9//H3hwyQAIGEISUJEoZAZXCCMjhQKlJwQGIr\niIJERGgriFaLFcVqW+NQxZ9SCy0gEsQyFEEiYltBsU6AAaIYxjCEJIRAGJIwhdzk+/tjrcPdOTn3\nnnVzp31zP6/nOc85Z++19157OPu791prr6OIwMzMrMQmg50BMzMbOhw0zMysmIOGmZkVc9AwM7Ni\nDhpmZlbMQcPMzIo5aNiAknSxpC8Mdj4GW3fbQdIHJP1yoPNkVsJBY5iS9LCkFyQ9K+lpST+StONg\n56tKUkjabbDzMZRJuknShyQdl/f1s3m/r618fzanrR4Tjde38rgP5P3x/5rmf1QefnGbfEzN6a5v\nGn6ppM9Xvm8t6TxJj0l6XtKdkk7sq+1hveegMbwdGRFbADsAS4F/HeT89Bslw/Z4j4jvRcQWeX+/\nFXi08T0PaziyOjwiTquMewA4RtLIyrAZwH09yMoBkl7faoSk0cANwE7AQcBWwBnAlyV9vAfLsH40\nbH9E1ikiXgSuAvZsDJO0laRLJD0haYGksxon3Xwl+P1K2q9IujGfmA+RtEjSpyUty1evx3W1bEkn\nS5ov6SlJsyVNysP/Lyf5Xb7ifU+LaUdIOjsv5yFJp+Wr2ZF5/E2SZkr6FfA8sIukSXk5T+XlnlyZ\n3zpFRo11qXx/WNKZku7Kd2ffkbRZZfw7JM2V9IykX0t6VWXcayXdLmmlpCuAl6fretPoW5KWS7pH\n0qF54NGSbmtK+HFJ17aZX194DLgTODwvdwLwemB2D+bxL8DMLsa9H3gFcHREPBQRqyPiv4HTgX+S\nNG6Dc259xkHDkDQWeA9wc2Xwv5Ku9HYB/hQ4AWgUE3wC2CcXWbwJOAmYEZ190vwRsC0wmXQler6k\nPVos983Al4BjSHc7C4DLASLi4Jzs1fmK94oWWT+ZdNX8GuB1wPQWad4PnAJsWZn/ImAS8G7gizkf\npY4jnTR3BXYHzsrr8lrgIuCvgG2A/wBmS9o0X0H/APguMAH4L+Av2yznANKV/bbA54Cr80l6NrCz\npFc2reMlPViH3riEdCwAHAtcC6zqwfTnArtLekuLcYcBP46I55qGf58UZA/qYV6tHzhoDG8/kPQM\nsJz0g/0qpCt40gnhzIhYGREPA2eTTk5ExPP589eBS4GPRMSipnl/NiJWRcTPgR+RAkOz44CLIuL2\niFgFnAkcJGlqYf6PAb4ZEYsi4mngyy3SXBwR8yKigxTM3gD8fUS8GBFzgQvpPAmW+FZELIyIp0hX\nzO/Nw08B/iMibomINRExi3QyPTC/RgHfyFfPVwG/bbOcxyvprwDuBd6et9MVwPEAkvYCpgLX9WAd\nuvODfKfUeJ3cNP4a4BBJW5G2W0+D1Quk7daqEcC2wJLmgXnfLcvjbZA5aAxv0yNia9JV3GnAzyU1\n7hJGka7MGxaQ7hwAiIhbgAcBAVc2zffppqvFBaQr+2aTqsuIiGeBJ6vLaWMSsLDyfWGLNNVhk4Cn\nImJlU95Kl9c8v+p67QR8onrCBXbM4ycBiyt3Yo1pu9MqfWNZs4D3SRIpeF+Zg0lfmB4RW1deF1RH\nRsQLpIuAs4BtIuJXG7CMC4GJko5sGr6MdMe5jlzcuG0eb4PMQcPIV8ZXA2uAN5J+nKtJJ8KGVwCL\nG18knQpsCjwKfLJpluMlbd407aMtFv1odRl5mm2qy2ljCTCl8r1V66/qifdRYIKkLZvy1ljec8DY\nyri/ZP2r2+oyquu1EJjZdMIdGxGX5XxOzif56rTdaZX+UYCIuBl4CXgT8D5SsddAuoRURHnphkwc\nES8B/wj8M+mio+EG4K1Nxw6k/bCKdYtPbZA4aFijZdFRwHjg7ohYQ7p7mClpS0k7AR8nnyQk7U4q\nXjiedKX7SUmvaZrtP0oanes83kEqx292GXCipNdI2hT4InBLLg6D1KJrl26yfiXwUUmTJT0CfKW7\n9YyIhcCvgS9J2ixXVJ9E58lvLvA2SRPyHdefsP7V7amSpuT6hc+QiooALgD+WtIBeXseLOm3+Y7j\nGlIwvFTSKEl/AezfXV6B7YHTc/qjgVcC1eaqlwDfAlZHxMvPdOTK/w+1mXdv/ZxUnNmb1nbfJd3h\nHtE0bBHwX0pNdEdJOhw4B/h8RCzvxfKsjzhoDG8/VGqjv4JUzjwjIublcR8hXXk/CPwS+E/golxU\ncCnwlYj4XUTcD3wa+G4+8UNqZfM06cr4e8BfR8Q9zQuPiBuAz5IqOpeQKpePrST5PDArF/e0qhO5\nAPhf4PekYo1bgA7SHVNX3kuqA3iUdDL/XM4HpJPW74CH83xbVb7/Zx73IKmi+gt5XeaQKua/Rdqe\nN5HuxF5NChgnAW8DniI1Ori6mzyS12UaKWjNBN4dEU9Wxn8X2JsNvNrvxg+17nMa1zQniOTGXK+z\nQfKFyT+QGgY0hq0C3kK6a7uFtB2/DnwmIr66ocuyPhYRfvnVZy/gEGDRICz3YVJF+oIW404G5pNO\n2LOBSZVxf06qZF5Oatnzc+BDedwHgF9W0i4GbsvzWQp8uou8/BL4tzb5bZknUkALYGQl7U3NeQK+\nkdMtBN6ax80kBcwXgWdJlfaDfkz4tXG9fKdhQ5akMZLelu9+RpCKyq5pStNls15J25KeTzmTdDdw\nL+m5g1bL2hKYSGr1NAnYDbixRbqxpKahV3WT7y7zVOiAnIefkYr0vi1JEfEZ4BfAabH+g3lmfcJB\nw4YykSpUnyadRB8hFXlUddes923AvIi4OlKzznNIRWutvIN0FX9VpOa6KyO1IGs2nvS7Wq/paGGe\nSh1AqoyeRQo8E3swbb/Qul2VVF/z2k9tQ4WDhvWpiLgpIqa0T9kny3o+Iv4kIrYkFdN8LSJWNCXr\nrlnvOk12IyJIFbGt7Aj8MDrrP7ryNLCWFk1HC/NU4paI2Cki7oj0zAzAFt1OMQCi0lVJ02uvwc6b\n9R0HDdvYddesd50mu7mJa1cBbyHdt+QCXn7w8Td0/8R3d3lqPN9Sbfr7R+2WW81CD9Ka9ZiDhm1M\nRuWmtI3XSLpv1vsjUnco03PaU+n6BH0dsIOkj+WuQbaUdEAXaT8JfEDSGZK2AZD0akmNeosu8xQR\nT5CCx/FKfWt9kNSqrFS7ZspmveKgYRuT60ndVDRen49umvVGxDLgaFInek+SOmycQ4u+lCI9RX4Y\ncCSp3uN+4M9aZSIifg28Ob8elPQUcH7OH93lKTuZ1Lvrk8BepGdLSn0TeLdSh4rn9GA6syJKxbhm\nptSL7yLguIj42WDnx6yOfKdhw5qkw5X++GdT0kOKwt1VmHXJQcOGu4NIT3YvIxU9TY/UKZ+ZteDi\nKTMzK+Y7DTMzK+agYWZmxUa2TzK4xo0bF9tvv/1gZ8PMbKP0wAMPLIuI7UrT1z5obL/99px99tmD\nnQ0zs43S9OnT2/2L5DpcPGVmZsUcNMzMrJiDhpmZFXPQMDOzYg4aZmZWzEHDzMyKOWiYmVkxBw0z\nMyvmoGFmZsUcNMzMrJiDhpmZFXPQMDOzYg4aZmZWzEHDzMyKOWiYmVkxBw0zMyvmoGFmZsUcNMzM\nrJiDhpmZFXPQMDOzYg4aZmZWzEHDzMyKOWiYmVkxBw0zMyvmoGFmZsUcNMzMrJiDhpmZFSsKGpL+\nVtI8SX+QdJmkzSRNkPQTSffn9/GV9GdKmi/pXkmHV4bvK+nOPO4cSeqPlTIzs/7RNmhImgycDuwX\nEXsDI4BjgU8BN0bENODG/B1Je+bxewFHAOdKGpFndx5wMjAtv47o07UxM7N+VVo8NRIYI2kkMBZ4\nFDgKmJXHzwKm589HAZdHxKqIeAiYD+wvaQdgXETcHBEBXFKZxszMhoC2QSMiFgNfAx4BlgDLI+J/\ngYkRsSQnewyYmD9PBhZWZrEoD5ucPzcPNzOzIaKkeGo86e5hZ2ASsLmk46tp8p1D9FWmJJ0iaY6k\nOStWrOir2ZqZWS+VFE+9BXgoIp6IiNXA1cDrgaW5yIn8/nhOvxjYsTL9lDxscf7cPHw9EXF+ROwX\nEfuNGzeuJ+tjZmb9qCRoPAIcKGlsbu10KHA3MBuYkdPMAK7Nn2cDx0raVNLOpArvW3NR1gpJB+b5\nnFCZxszMhoCR7RJExC2SrgJuBzqAO4DzgS2AKyWdBCwAjsnp50m6Ergrpz81Itbk2X0YuBgYA/w4\nv8zMbIhoGzQAIuJzwOeaBq8i3XW0Sj8TmNli+Bxg7x7m0czMasJPhJuZWTEHDTMzK+agYWZmxRw0\nzMysmIOGmZkVc9AwM7NiDhpmZlbMQcPMzIo5aJiZWTEHDTMzK+agYWZmxRw0zMysmIOGmZkVc9Aw\nM7NiDhpmZlbMQcPMzIo5aJiZWTEHDTMzK+agYWZmxRw0zMysmIOGmZkVc9AwM7NiDhpmZlbMQcPM\nzIo5aJiZWTEHDTMzK+agYWZmxRw0zMysmIOGmZkVc9AwM7NiDhpmZlbMQcPMzIo5aJiZWTEHDTMz\nK+agYWZmxYqChqStJV0l6R5Jd0s6SNIEST+RdH9+H19Jf6ak+ZLulXR4Zfi+ku7M486RpP5YKTMz\n6x+ldxrfBP47Iv4YeDVwN/Ap4MaImAbcmL8jaU/gWGAv4AjgXEkj8nzOA04GpuXXEX20HmZmNgDa\nBg1JWwEHA98GiIiXIuIZ4ChgVk42C5iePx8FXB4RqyLiIWA+sL+kHYBxEXFzRARwSWUaMzMbAkru\nNHYGngC+I+kOSRdK2hyYGBFLcprHgIn582RgYWX6RXnY5Py5efh6JJ0iaY6kOStWrChfGzMz61cl\nQWMk8DrgvIh4LfAcuSiqId85RF9lKiLOj4j9ImK/cePG9dVszcysl0qCxiJgUUTckr9fRQoiS3OR\nE/n98Tx+MbBjZfopedji/Ll5uJmZDRFtg0ZEPAYslLRHHnQocBcwG5iRh80Ars2fZwPHStpU0s6k\nCu9bc1HWCkkH5lZTJ1SmMTOzIWBkYbqPAN+TNBp4EDiRFHCulHQSsAA4BiAi5km6khRYOoBTI2JN\nns+HgYuBMcCP88vMzIaIoqAREXOB/VqMOrSL9DOBmS2GzwH27kkGzcysPvxEuJmZFXPQMDOzYg4a\nZmZWzEHDzMyKOWiYmVkxBw0zMyvmoGFmZsUcNMzMrJiDhpmZFXPQMDOzYg4aZmZWzEHDzMyKOWiY\nmVkxBw0zMyvmoGFmZsUcNMzMrJiDhpmZFXPQMDOzYg4aZmZWzEHDzMyKOWiYmVkxBw0zMyvmoGFm\nZsUcNMzMrJiDhpmZFXPQMDOzYg4aZmZWzEHDzMyKOWiYmVkxBw0zMyvmoGFmZsUcNMzMrJiDhpmZ\nFXPQMDOzYsVBQ9IISXdIui5/nyDpJ5Luz+/jK2nPlDRf0r2SDq8M31fSnXncOZLUt6tjZmb9qSd3\nGh8F7q58/xRwY0RMA27M35G0J3AssBdwBHCupBF5mvOAk4Fp+XVEr3JvZmYDqihoSJoCvB24sDL4\nKGBW/jwLmF4ZfnlErIqIh4D5wP6SdgDGRcTNERHAJZVpzMxsCCi90/gG8ElgbWXYxIhYkj8/BkzM\nnycDCyvpFuVhk/Pn5uFmZjZEtA0akt4BPB4Rt3WVJt85RF9lStIpkuZImrNixYq+mq2ZmfXSyII0\nbwDeKeltwGbAOEmXAksl7RARS3LR0+M5/WJgx8r0U/Kwxflz8/D1RMT5wPkAu+22W58FIzMz6522\ndxoRcWZETImIqaQK7p9GxPHAbGBGTjYDuDZ/ng0cK2lTSTuTKrxvzUVZKyQdmFtNnVCZxszMhoCS\nO42ufBm4UtJJwALgGICImCfpSuAuoAM4NSLW5Gk+DFwMjAF+nF9mZjZE9ChoRMRNwE3585PAoV2k\nmwnMbDF8DrB3TzNpZmb14CfCzcysmIOGmZkVc9AwM7NiDhpmZlbMQcPMzIo5aJiZWTEHDTMzK+ag\nYWZmxRw0zMysmIOGmZkVc9AwM7NiDhpmZlbMQcPMzIo5aJiZWTEHDTMzK+agYWZmxRw0zMysmIOG\nmZkVc9AwM7NiDhpmZlbMQcPMzIo5aJiZWTEHDTMzK+agYWZmxRw0zMysmIOGmZkVc9AwM7NiDhpm\nZlbMQcPMzIo5aJiZWTEHDTMzK+agYWZmxRw0zMysmIOGmZkVaxs0JO0o6WeS7pI0T9JH8/AJkn4i\n6f78Pr4yzZmS5ku6V9LhleH7SrozjztHkvpntczMrD+U3Gl0AJ+IiD2BA4FTJe0JfAq4MSKmATfm\n7+RxxwJ7AUcA50oaked1HnAyMC2/jujDdTEzs37WNmhExJKIuD1/XgncDUwGjgJm5WSzgOn581HA\n5RGxKiIeAuYD+0vaARgXETdHRACXVKYxM7MhoEd1GpKmAq8FbgEmRsSSPOoxYGL+PBlYWJlsUR42\nOX9uHm5mZkNEcdCQtAXwfeBjEbGiOi7fOURfZUrSKZLmSJqzYsWK9hOYmdmAKAoakkaRAsb3IuLq\nPHhpLnIivz+ehy8GdqxMPiUPW5w/Nw9fT0ScHxH7RcR+48aNK10XMzPrZyWtpwR8G7g7Ir5eGTUb\nmJE/zwCurQw/VtKmknYmVXjfmouyVkg6MM/zhMo0ZmY2BIwsSPMG4P3AnZLm5mGfBr4MXCnpJGAB\ncAxARMyTdCVwF6nl1akRsSZP92HgYmAM8OP8MjOzIaJt0IiIXwJdPU9xaBfTzARmthg+B9i7Jxk0\nM7P68BPhZmZWzEHDzMyKOWiYmVkxBw0zMyvmoGFmZsUcNMzMrJiDhpmZFXPQMDOzYg4aZmZWzEHD\nzNZx1jNncdYzZw12NqymSvqeMrNh5Atbf2Gws2A15jsNMzMr5qBhZoPKxWFDi4unzGxQDcfisEaQ\nHIrr7qBhZjbAhmKwaHDxlJmZFXPQMDOzYg4aZmZWzEHD+p1bx9hQ4uO1e64It343lCv9bPjx8do9\n32mY9RNfsdrGyHcaZv3EV6y2MfKdhpmZFXPQMDOzYg4aZmZWzEHDzMyKOWiYmVkxBw0zMyvmoGFm\nZsUcNMyGiYF82HA4P9i4sa+7H+4zGyYG8mHD4fxg48a+7r7TMDOzYg4ahTb2W04zsxIuniq0sd9y\nWs/V9X+e65ovW99Q3FcDHjQkHQF8ExgBXBgRXx7oPAwXQ/GAbKdO61SHPLRS13x1p7v92pf7vE7H\nD5Tlo255VkQM3MKkEcB9wGHAIuC3wHsj4q6uptltt93i7LPPHqAcDp66HRg2vPXV8dhuPj7uB9/0\n6dNvi4j9StMPdNA4CPh8RByev58JEBFf6mqa4RI0bONUetLsLs1w1qoesbu7ka7SDMXtPFABte5B\n493AERHxofz9/cABEXFaV9NsSNAYigdIT9Tp6qxOeakrb6OBMVS382Dne6MIGpJOAU4B2G677fa9\n4IILXh5XeuXRnLa7K4/SNCVXOBu6rJLl1S3PTtN9mlbpB/NYLUlXzWdXee7r47m/i8BK0w/kb7m7\nfPRkPn2R57oHDRdPmZnVSE+DxkA/p/FbYJqknSWNBo4FZg9wHszMbAMNaJPbiOiQdBrwP6QmtxdF\nxLyBzIOZmW24AX9OIyKuB64f6OWamVnvuRsRMzMr5qBhZmbFHDTMzKyYg4aZmRVz0DAzs2ID+nDf\nhpC0GljbYtRqYFSbyZ3GaZzGaZym+zSbRES7aV82FILGGlrfEa3tYrjTOI3TOI3TlKdZGxEj2kz7\nMhdPmZlZMQcNMzMrNhT+7vW3wPYthj/exXCncRqncRqnKU/zeJvp1lH7Og0zM6sPF0+ZmVkxBw0z\nMyvmoGFmZsVqUxEu6XhgAvApYGIefDvwY2AKMA5YkV+/A7bJ76cDdwCbAk8B00iVPZsAWwGPATsD\nL5EebPkuMBnYAdgCGAM8DXQAvwQOAXYBHgYWAJPyfEbnNDsDT+T8PAc8DzyT57Mkvy8CXgmMBZTH\nTwJ+DbwuT7sQ2DyPvzOv70HA8pz354DN8vpOJv3/yBjgLmA8sIb0vyQ7AH+Sp5mX13+z/P2H+fsC\n4GAg8vzW5m2xM/DzPP9HGrsCeHNexqK8TRblabYG3pTnMTbPb9u8fj8D9gTmAgfkeW0D3ALsnV8v\nAPfm7fl03mfLge3y5z8CVgFLSQ0gNgF+AszM671TTteRp58CLCMdx/Pz9EuBXfM675rTb52HP5rz\nvRzYMq/j7cBUYD/ggbyP3pq3ySLguvx+dJ7/o3lfvJK0v3+Xl9NBOu6W5nV4EViZ83kY6RjdJuf1\nhZz3ucBupIrIV+X9d0fejnvlde7IeVmZ138l6ThYTTqGpuVtOhX4PbBjHv8bYB/Scbsz8AfSPv9N\nzs9jedpf5WV15HytzPvqV3m7LcjbZiTp9/IY8Md5O2yf874s7W4ezfmYA+yft9PzOf+35e20Rd4m\n2+Xt94qcpz1Jx+1iYI883zH5XXm//GneriPzvns6pxkL3J3ntVWe76TKMqvD5uT1W1sZ9nRe9jak\nY+OnpN/iXcCBwIN5/4zO63N/nu4l0jnntTnN8rwv3przuyudx8O++X1y3oaT83xuJv2mgnQMb5vX\nd2J+fy7vkz3yPlyS98s2eV/PI50DXiT9hvfJ+2wf0vEwjfQ7ega4iXRum0zn+fLciLhV0hbA5hGx\nlDZqUxEu6RbShi1+yMTMzHotSBcNyyJiUrvEdSqeGkUKGPWIYmZmw4NI598pJYnrFDTGVD47cJiZ\nDaCIaNXH33rqFDS+nd+VX2ZmNjCKL9RrEzQi4mvA39JZIfsMqbJ3Leuu0Jr8Cvr+jqR5fkWRdxC1\n2wal2yfofl1LtnXz9L3dN8G6y+3Lfd2T7TIUbUi++2I7N6at+++mO311Xunp9izdZl3Nryd5bj6f\nvgB8sXTi2lSEA0hq7LB3AT+NiJWDnCUzs42WpH2B95FaBy6KiNe3m6ZOTW5Pr3ydAZwhaX9SHodS\ncVWQmtaNpn/u5BqBtbt5B6kJ3mZs+LZbTWouOHkD5rGWtA3GtEtYEcCzpKawJWkb770tzgxSs963\nsOH7q3rltZbetwBsvpLrq+O/cUfZWM/ezrc6v778jfbn+vf1fPtynstJv9lNezGPhmq+2uXpWeDd\npDuOtmpzpyFpOen5BTMzGzhr8vu5EXF6tympUZ0G6eEYMzMbWI27xdtKEtcpaPRHhafZUOXfgQ2U\nkaRSp1kliesUNKrlbh0M3R9NAPcw+PlfMMjL3xA3F6abS+puoq+saZ+krWvo233+CVL3JX3dauwy\nUlcYfeEPpG4s+toaUnccPclnyXYKUr3B0xuSqW6sInU50pv5PtNHeWl4qQdpReq+pixxjeo0dif1\nobKC1JfNpfn79qQN+iSpb6AbSH23vAG4ntQfzT+T+q45iNRn1CMRcV+e77akvpkmAdfSeXAdTKr8\nOYfU58sHgYdIfShNAY4i9e00htTn0Bw6+yo6BPgb4Kr8/RV53OyIWNW0XocC/0AK0F+KiOslidQ3\nTwBvz3n+RUTMr0zXSLMVqa5nCXBfRDzRlOYwUkXu8aQf2U0R8WQlzQ7AR/JylkXEoU3TT8t5j7wN\n74mImytpXg18jFRBfVEl/9uQ+taZD7wnL/sPETGnxfp/ADghT9Poe2tRXreOiLixaZpGnt9M6pfo\n9jzq8ohYTZPKNu4A3hL5oK7k83U56XJSvz37kI6l/2vaVkcDZ5GOwS9FxPVN23kPUr9jj+R1v7t5\nfZvmdXp1PpVxjX27P6nBwl2k43xhm/mtl7cW83wz6bcyj9TP0BbAb1vNN+/bM0n9aK1zbFTm+QFS\nxb5I2/eZ5u2W03Z5nLVZ70Ye7wPmNs+3ad6Hk34Ht0bEPzX2b0Qsy7/zbUn9uZ1BOq6fBM5rld/K\nvNf7fRZsg22AO5qP25JtUfnNTSX9Dh4l7Z/VlTSNfb2M1ECj8RuFVGkdpHPU64Afkc6Tu3a1DSVt\nQ2dfXU/l/L8K+EvS+fNW4GsRcVer9Vlv/WoUNLaOiGcq3w8mney/RmeLpEZLmZGkq5FNSBE1SC0O\nmu+cXiKdnM4gHZxnkU5UrbxACgzfIjU/25dU1tdY5hOkA3JKXlajv5YOOp8nGZuXObrN6i6v5EOV\nYY3WRmvzPMdUxo/oYh2brSKdMBrtvhs7uDGfpaTO4pQ/nw+cmtdrLOkAbJf/BjW995fnSBcIf0dq\nHvinlXGLSS28urOY1MneJNJ26aBzHRud7T1LOnlB2vYvsX7rrzWkY28taV/sRGrtspbU2mwT1t0/\n1W0fdB6zjTSNvPTm+Okuzfg8v0Zrvqq1lWV1dUxtkvPdOGGOJnU30df7O0jB6EHWvWOoHqsNjc+P\n0XnsjiN1drpTzmOjdeFQaXW5hnSe+jfgQuCrrHtMjyR1TjiV1i2r1pC23YkR8WtJ15OO+b1J2+J5\n0rnr1aTt02jd9xLpwvg04L0R8ZWSzNYpaHSQemG8jNTk9k2DmiGrq0YzW7ON0Qv0rKl6s7tJd44b\n4s6IeFW7RHWq07gb+Abp9toBw7rigGEbs94EDNjwgAFwZEmiOgWN1RFxHanOwszM+ldzMdMbSyaq\nU9CQpHnARYOdkY3cUOtfy4avnvZ3Zj3TfNd+TMlEtelGBPgeqQKooVF23VyG3ehG40FSqyXorKxu\n7r5hNal55smkVic/J1UotfIiqWXBo6SKoxWkyrn5+ftHK2kbnSYurwybSmqZsyGey/k6GpjelH9I\nDQIa//omOjtxrK5vB6lF0L1tllWtOF5M2u6fJbXQGJWXU3KL3KoSvLvO1JqbVDe6GSnpcuN5UkX4\nJyPi4YL065B0Nunf51bm5Y3No0aSWpFA2taj6DwRNV9QrSEdH6Py50a+R+dpG83EXyStVwetf1+N\nNGLdJqVT2fDjpzsPA38G/DWd61q1mnQcb9vNPMaTGpJMoLOCuV0nl12pVlCvJW2DB2jdRLy7Rg7V\nY3cyaT9MobPxSPMJsZHXdsWbrerMglRpvAnljUR6Yi2pIvxc4IKIWKfprqTxpJZ4Hyb9PpuPzbV0\nVoT/qjIVT1eoAAAIOklEQVTddFIDnl+T/sXzjXnaTUnruAlp/z8IHBcRc0syW5uKcHi5w8K1wOWk\n1i7jSU1Jf0BqRbEmIkY2TfNpUquYZhdFxO0thiNpMqkZ3YGkE8ga0gllc9JJoRWn6Z80y4Gzqwe7\nWZ3lxwOm5q+lLdn6Is1a0sXPWNLFQNVzpCDQ6oJvbkTcLul9pBZac0hB4xrg88COEfFim2W/rDZB\nQ9IIUlRstEeuXsn4L2DNzPrHD4CjIqKouqJOQeNCUgRdCHySst5czcysb6yMiLadxtYpaPy+0UY4\nF1OZmdkAiYii5ux1uoofLekMSd31A7SEVMFoZma91+PzaZ1aT80B/iV/7qCzdr8a/bYFvktqyXAU\nqU+orrS6W/GDYfW0htSaqivVLj6cxmkGMs0jpH7XJrHxnT8WA18C3kZqoFKkNsVT8HKx1HJSk7D7\nSf27/wWdf850R0S8rpJewO6k1jjN5kfEiv7NsZlZ/eVz5ZZ9cU6sTdCQ9E46u5c+n/SgyQQ2vuhu\nZlYXa4GfRsRhpRPUKWi8QCqmeJb0TEad6lvMzDZmL0TE2PbJ6nVivof0VPRnqVe+zMw2dsUdJdap\nIjyA35O6WDAzs/61QX8zUKegIVLfMY0/ZOmPfnjMzCypBoxziyeqUZ3GIaS/WoXU9O3Z/LnRjngk\nKaAso7PDQEhdjLQqzlrrNE7jNE7jNC3TrCL9h9EFEXF1i/Rdqs2dRkTcJGklqU30k6R2w2NIf/kI\nqZ30atJ/Gi9j/f6omjv8WuM0TuM0TjOM00wg/X3z+1n30YQOUi/eT5L+px1JB0TELRSo053GK0gP\n970bd1BoZjZQ7gV2L+2wsE6tlK4gPaexKel/cs3MrH8F6S6kuEK8NsVTpC5CtgBm0Pv/yTUzs/aG\ndOup24ALaf8Xj2ZmNkjqVKcxms5O614ENsufl5EqxXcmBZQOum4dsAndtz12GqdxGqcZDmk6crrN\nWqRZA8wG/odUWT4GOCEipnYxr3XUJmgASGr8U9+/A39FWrn3kGr6byBtpHc2TVbyTIfTOI3TOI3T\nrJ/m1oh4vE36ddQtaHwV+LvBzoeZ2TDxFHAC8JuIeKpkgtoEDUlfBN4I3A58dJCzY2Y2nDwUEbuU\nJKxT0LgTeG1EdFSKqdwtuplZ/+oAbouIA0sS1+k5jZHADEmNf+1zwDAz618PAd8DXlk6QZ3uNK4D\n3p6/LgXGA4tI3Yds1tV0Zma2wZZGRHd/m72eOgWNMcDzABEhSaOATwGvIQWQP8tJ1zRN+hIwus3s\nncZpnMZpnGb9NBERo9qkX0dtggZALppyv1NmZgNrbUQUnXtrU6ch6ePAPwFPD3ZezMyGkcWkfv+K\n1OZOI3eLfj0wDziLFDy2H9RMmZlt5CKiR42OanOnAexFys/xwCgcMMzMaqc2dxoAklaQ/oQJWver\n0uhzpaOSZi3d14M4jdM4jdM4Tes0L0TEuG7Sr6duQSNIK/ULYBc6/zP8OOA/8+eHImLXQcukmdkw\nVqfiqaqPAVflzxERl1XGXTQI+TEzM2p0pyFpAvAz4FVNo4JUs/9OUtfpm0TE2AHOnpmZUa87jWXA\nOGBJ/r6cVHfxGPAuYHZEbDFIeTMzM+oVNM4g/cH54cCqiNia1I3IauD3wMGSbsN9UpmZDZraFE8B\nSFoKbEcKDI2nwxtBovFPVKN72q7YzMz6Rp3uNCA9m9EICM3NxkR6cvFvBjRHZmb2sroFjbNIFd+Q\n/if8q40RETEyInaJiH8flJyZmVl9iqck/T3wXuBy4ERg9+p4F0mZmQ2+OgWN+4C9ImJ1/v7HwBxg\nc3DQMDOrgzoVT60l/eESABFxT25i+0HgkUHLlZmZvWzkYGeg4mPAryQ9SWf36BOAfQAkfRC4IyLu\nGKT8mZkNe7UpnoKX+57qloupzMwGT52KpyD9N3ijF8a/rQaIiJADhpnZ4KrVnQaApPcD3yE9p/EU\nqYjKdxhmZjVQu6DRIOkXwBsb3x00zMwGX92Kp5D0WUnLgdfnQQE8JemvBjFbZmZGze40JD1O6nsK\n4KX82pT0968A90XEHoORNzMzq1/QaGRmXESsrAzfDngcXExlZjaYalc8lb2l6fu7BiUXZma2jjo9\n3AdwAylgXC21vKGYNbDZMTOzqloVTwFIGgWcD/w5MAZYCVwBfDYiVg1m3szMhrvaBQ0zM6uvutZp\nmJlZDTlomJlZMQcNMzMr5qBhw5qkZyXtI2lufj0l6aH8+QZJUyW9UBk/V9IJedqHc3c31fnNlfSH\nbpZ3iKSQdGRl2HWSDsmfR0v6hqT5ku6XdK2kKf20+mY9Vrcmt2YDLiLuBF4DIOli4LqIuCp/nwo8\nEBGv6WLyLSXtGBELJb2ycJGLgM8AP2wx7ovAlsAeEbFG0omkJugHhFutWA34TsOsd64E3pM/vxe4\nrGCa3wHLJR1WHShpLHAi6W8B1gBExHeAVcCb+yzHZr3goGHW3q5NxVNvqoz7PvAX+fORtL57aGUm\ncFbTsN2ARyJiRdPwOcBePc20WX9w8ZRZe90VTz0JPC3pWOBu4PmSGUbE/0lC0hvbpzarD99pmPXe\nFcC/UVY0VdV8t/EA8ApJWzal2xeYt+HZM+s7DhpmvXcN8C/A//Rkooj4X2A88Kr8/TlS/2pflzQC\nILfUGgv8tC8zbLahHDTM2muu0zi9OjIiVkbEVyLipQ2Y90xgx8r3M4EXgfsk3Q8cDbzLLaesLtz3\nlJmZFfOdhpmZFXPrKbN+IOlw4CtNgx+KCP+hmA1pLp4yM7NiLp4yM7NiDhpmZlbMQcPMzIo5aJiZ\nWTEHDTMzK/b/AWE6Gg5o/y+0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x243f9a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the boxplot\n",
    "df.boxplot(column='Logic Count', by='ITEM_NO', rot=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plots and histograms\n",
    "- Bar plots for discrete data counts\n",
    "- Histograms for continuous data counts\n",
    "- Look at frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing multiple variables with scatter plots\n",
    "\n",
    "Boxplots are great when you have a numeric column that you want to compare across different categories. When you want to visualize two numeric columns, scatter plots are ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sca!er plots\n",
    "- Relationship between 2 numeric variables\n",
    "- Flag potentially bad data\n",
    " - Errors not found by looking at 1 variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEbCAYAAAAibQiyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15814b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and display the first scatter plot\n",
    "df.plot(kind='scatter', x='Seafrigo Count', y='Logic Count', rot=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ITEM_NO', u' AMC Item Number ', u'ITEM_DESC', u'Logic Count',\n",
       "       u'Seafrigo Count', u'Discrepancy (cases)', u' Discrepancy Value ',\n",
       "       u'ACTIVE/INACTIVE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy data\n",
    "\n",
    "- Tidy Data paper by Hadley Wickham, PhD\n",
    "- Formalize the way we describe the shape of data\n",
    "- Gives us a goal when forma!ing our data\n",
    "- Standard way to organize data values within a dataset\n",
    "\n",
    "### Principles of tidy data\n",
    "- Columns represent separate variables\n",
    "- Rows represent individual observations\n",
    "- Observational units form tables\n",
    "- Be!er for reporting vs. be!er for analysis\n",
    "- Tidy data makes it easier to fix common data problems\n",
    "\n",
    "### Converting to tidy data\n",
    "- The data problem we are trying to fix:\n",
    " - Columns containing values, instead of variables\n",
    "- Solution: pd.melt()\n",
    "\n",
    "### Recognizing tidy data\n",
    "\n",
    "For data to be tidy, it must have:\n",
    "- Each variable as a separate column.\n",
    "- Each row as a separate observation.\n",
    "\n",
    "As a data scientist, you'll encounter data that is represented in a variety of different ways, so it is important to be able to recognize tidy (or untidy) data when you see it.\n",
    "\n",
    "### Reshaping your data using melt\n",
    "\n",
    "Melting data is the process of turning columns of your data into rows of data. Consider the DataFrames from the previous exercise. In the tidy DataFrame, the variables Ozone, Solar.R, Wind, and Temp each had their own column. If, however, you wanted these variables to be in rows instead, you could melt the DataFrame. In doing so, however, you would make the data untidy! This is important to keep in mind: Depending on how your data is represented, you will have to reshape it differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_NO</th>\n",
       "      <th>AMC Item Number</th>\n",
       "      <th>ITEM_DESC</th>\n",
       "      <th>Logic Count</th>\n",
       "      <th>Seafrigo Count</th>\n",
       "      <th>Discrepancy (cases)</th>\n",
       "      <th>Discrepancy Value</th>\n",
       "      <th>ACTIVE/INACTIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44207509</td>\n",
       "      <td>L044207509</td>\n",
       "      <td>DRAWER, DELTA VARIO ATLAS 120MM</td>\n",
       "      <td>1335</td>\n",
       "      <td>2235</td>\n",
       "      <td>900</td>\n",
       "      <td>$25,945.19</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44207668</td>\n",
       "      <td>L044207668</td>\n",
       "      <td>TOILET PAPER, COTTENELLE</td>\n",
       "      <td>445</td>\n",
       "      <td>985</td>\n",
       "      <td>540</td>\n",
       "      <td>$17,813.36</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44207958</td>\n",
       "      <td>L044207958</td>\n",
       "      <td>LINER, TRASH CAN, DOM SM</td>\n",
       "      <td>259</td>\n",
       "      <td>759</td>\n",
       "      <td>500</td>\n",
       "      <td>$14,445.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44208068</td>\n",
       "      <td>L044208068</td>\n",
       "      <td>BLANKET, YC (G&amp;G)</td>\n",
       "      <td>371</td>\n",
       "      <td>811</td>\n",
       "      <td>440</td>\n",
       "      <td>$94,467.70</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44207583</td>\n",
       "      <td>L044207583</td>\n",
       "      <td>FOAMING SOAP, SQUARE M+G 5.4 oz</td>\n",
       "      <td>523</td>\n",
       "      <td>885</td>\n",
       "      <td>362</td>\n",
       "      <td>$63,712.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ITEM_NO  AMC Item Number                         ITEM_DESC  Logic Count  \\\n",
       "0  44207509       L044207509   DRAWER, DELTA VARIO ATLAS 120MM         1335   \n",
       "1  44207668       L044207668          TOILET PAPER, COTTENELLE          445   \n",
       "2  44207958       L044207958          LINER, TRASH CAN, DOM SM          259   \n",
       "3  44208068       L044208068                 BLANKET, YC (G&G)          371   \n",
       "4  44207583       L044207583   FOAMING SOAP, SQUARE M+G 5.4 oz          523   \n",
       "\n",
       "   Seafrigo Count  Discrepancy (cases)  Discrepancy Value  ACTIVE/INACTIVE  \n",
       "0            2235                  900         $25,945.19            False  \n",
       "1             985                  540         $17,813.36            False  \n",
       "2             759                  500         $14,445.00            False  \n",
       "3             811                  440         $94,467.70            False  \n",
       "4             885                  362         $63,712.00            False  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Logic Count  Seafrigo Count variable     value\n",
      "0         1335            2235  ITEM_NO  44207509\n",
      "1          445             985  ITEM_NO  44207668\n",
      "2          259             759  ITEM_NO  44207958\n",
      "3          371             811  ITEM_NO  44208068\n",
      "4          523             885  ITEM_NO  44207583\n"
     ]
    }
   ],
   "source": [
    "# Melt airquality: airquality_melt\n",
    "airquality_melt = pd.melt(df, id_vars=['Logic Count', 'Seafrigo Count'])\n",
    "\n",
    "# Print the head of airquality_melt\n",
    "print(airquality_melt.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing melted data\n",
    "\n",
    "When melting DataFrames, it would be better to have column names more meaningful than variable and value.\n",
    "\n",
    "The default names may work in certain situations, but it's best to always have data that is self explanatory.\n",
    "\n",
    "You can rename the variable column by specifying an argument to the var_name parameter, and the value column by specifying an argument to the value_name parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ITEM_NO  Seafrigo Count        Logic Count     ITEM_DESC\n",
      "0  44207509            2235   AMC Item Number    L044207509 \n",
      "1  44207668             985   AMC Item Number    L044207668 \n",
      "2  44207958             759   AMC Item Number    L044207958 \n",
      "3  44208068             811   AMC Item Number    L044208068 \n",
      "4  44207583             885   AMC Item Number    L044207583 \n"
     ]
    }
   ],
   "source": [
    "# Melt airquality: airquality_melt\n",
    "airquality_melt = pd.melt(df, id_vars=['ITEM_NO', 'Seafrigo Count'], var_name='Logic Count', value_name='ITEM_DESC')\n",
    "\n",
    "# Print the head of airquality_melt\n",
    "print(airquality_melt.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting data\n",
    "\n",
    "While melting takes a set of columns and turns it into a single column, pivoting will create a new column for each unique value in a specified column.\n",
    "\n",
    ".pivot_table() has an index parameter which you can use to specify the columns that you don't want pivoted: It is similar to the id_vars parameter of pd.melt(). Two other parameters that you have to specify are columns (the name of the column you want to pivot), and values (the values to be used when the column is pivoted).\n",
    "\n",
    "### Pivot: un-melting data \n",
    "- Opposite of melting\n",
    "- In melting, we turned columns into rows\n",
    "- Pivoting: turn unique values into separate columns\n",
    "- Analysis friendly shape to reporting friendly shape\n",
    "- Violates tidy data principle: rows contain observations\n",
    " - Multiple variables stored in the same column\n",
    " \n",
    "### Resetting the index of a DataFrame\n",
    "\n",
    "There's a very simple method you can use to get back the original DataFrame from the pivoted DataFrame: .reset_index()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print the index of airquality_pivot\n",
    "print(airquality_pivot.index)\n",
    "\n",
    "# Reset the index of airquality_pivot: airquality_pivot\n",
    "airquality_pivot = airquality_pivot.reset_index()\n",
    "\n",
    "# Print the new index of airquality_pivot\n",
    "print(airquality_pivot.index)\n",
    "\n",
    "# Print the head of airquality_pivot\n",
    "print(airquality_pivot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting duplicate values\n",
    "\n",
    ".pivot_table() method when there are multiple index values you want to hold constant during a pivot. In the video, Dan showed you how you can also use pivot tables to deal with duplicate values by providing an aggregation function through the aggfunc parameter. Here, you're going to combine both these uses of pivot tables.\n",
    "\n",
    "Let's say your data collection method accidentally duplicated your dataset. Such a dataset, in which each row is duplicated, has been pre-loaded as airquality_dup. In addition, the airquality_melt DataFrame from the previous exercise has been pre-loaded. Explore their shapes in the IPython Shell by accessing their .shape attributes to confirm the duplicate rows present in airquality_dup.\n",
    "\n",
    "You'll see that by using .pivot_table() and the aggfunc parameter, you can not only reshape your data, but also remove duplicates. Finally, you can then flatten the columns of the pivoted DataFrame using .reset_index().\n",
    "\n",
    "NumPy and pandas have been imported as np and pd respectively."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Pivot airquality_dup: airquality_pivot\n",
    "airquality_pivot = airquality_dup.pivot_table(index=['Month', 'Day'], columns='measurement', values='reading', aggfunc=np.mean)\n",
    "\n",
    "# Reset the index of airquality_pivot\n",
    "airquality_pivot = airquality_pivot.reset_index()\n",
    "\n",
    "# Print the head of airquality_pivot\n",
    "print(airquality_pivot.head())\n",
    "\n",
    "# Print the head of airquality\n",
    "print(airquality.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond melt and pivot\n",
    "\n",
    "### Beyond melt and pivot\n",
    "- Melting and pivoting are basic tools\n",
    "- Another common problem:\n",
    " - Columns contain multiple bits of information\n",
    " \n",
    "### Splitting a column with .str\n",
    "\n",
    "The dataset you saw in the video, consisting of case counts of tuberculosis by country, year, gender, and age group, has been pre-loaded into a DataFrame as tb.\n",
    "\n",
    "In this exercise, you're going to tidy the 'm014' column, which represents males aged 0-14 years of age. In order to parse this value, you need to extract the first letter into a new column for gender, and the rest into a column for age_group. Here, since you can parse values by position, you can take advantage of pandas' vectorized string slicing by using the str attribute of columns of type object.\n",
    "\n",
    "Begin by printing the columns of tb in the IPython Shell using its .columns attribute, and take note of the problematic column."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Melt tb: tb_melt\n",
    "tb_melt = pd.melt(tb, id_vars=['country', 'year'])\n",
    "\n",
    "# Create the 'gender' column\n",
    "tb_melt['gender'] = tb_melt.variable.str[0]\n",
    "\n",
    "# Create the 'age_group' column\n",
    "tb_melt['age_group'] = tb_melt.variable.str[1:]\n",
    "\n",
    "# Print the head of tb_melt\n",
    "print(tb_melt.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "      country  year variable  value gender age_group\n",
    "    0      AD  2000     m014    0.0      m       014\n",
    "    1      AE  2000     m014    2.0      m       014\n",
    "    2      AF  2000     m014   52.0      m       014\n",
    "    3      AG  2000     m014    0.0      m       014\n",
    "    4      AL  2000     m014    2.0      m       014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting a column with .split() and .get()\n",
    "\n",
    "Another common way multiple variables are stored in columns is with a delimiter\n",
    "\n",
    "Print the columns of ebola in the IPython Shell using ebola.columns. Notice that the data has column names such as Cases_Guinea and Deaths_Guinea. Here, the underscore _ serves as a delimiter between the first part (cases or deaths), and the second part (country).\n",
    "\n",
    "This time, you cannot directly slice the variable by position as in the previous exercise. You now need to use Python's built-in string method called .split(). By default, this method will split a string into parts separated by a space. However, in this case you want it to split by an underscore. You can do this on Cases_Guinea, for example, using Cases_Guinea.split('_'), which returns the list ['Cases', 'Guinea'].\n",
    "\n",
    "The next challenge is to extract the first element of this list and assign it to a type variable, and the second element of the list to a country variable. You can accomplish this by accessing the str attribute of the column and using the .get() method to retrieve the 0 or 1 index, depending on the part you want"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Melt ebola: ebola_melt\n",
    "ebola_melt = pd.melt(ebola, id_vars=['Date', 'Day'], var_name='type_country', value_name='counts')\n",
    "\n",
    "# Create the 'str_split' column\n",
    "ebola_melt['str_split'] = ebola_melt.type_country.str.split('_')\n",
    "\n",
    "# Create the 'type' column\n",
    "ebola_melt['type'] = ebola_melt.str_split.str.get(0)\n",
    "\n",
    "# Create the 'country' column\n",
    "ebola_melt['country'] = ebola_melt.str_split.str.get(1)\n",
    "\n",
    "# Print the head of ebola_melt\n",
    "print(ebola_melt.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "             Date  Day  type_country  counts        str_split   type country\n",
    "    0    1/5/2015  289  Cases_Guinea  2776.0  [Cases, Guinea]  Cases  Guinea\n",
    "    1    1/4/2015  288  Cases_Guinea  2775.0  [Cases, Guinea]  Cases  Guinea\n",
    "    2    1/3/2015  287  Cases_Guinea  2769.0  [Cases, Guinea]  Cases  Guinea\n",
    "    3    1/2/2015  286  Cases_Guinea     NaN  [Cases, Guinea]  Cases  Guinea\n",
    "    4  12/31/2014  284  Cases_Guinea  2730.0  [Cases, Guinea]  Cases  Guinea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating data\n",
    "\n",
    "### Combining data\n",
    "- Data may not always come in 1 huge file\n",
    " - 5 million row dataset may be broken into, 5 separate datasets\n",
    " - Easier to store and share\n",
    " - May have new data for each day\n",
    "- Important to be able to combine then clean, or vice versa\n",
    "\n",
    "### Combining rows of data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Concatenate uber1, uber2, and uber3: row_concat\n",
    "row_concat = pd.concat([uber1,uber2,uber3])\n",
    "\n",
    "# Print the shape of row_concat\n",
    "print(row_concat.shape)\n",
    "\n",
    "# Print the head of row_concat\n",
    "print(row_concat.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    (297, 4)\n",
    "              Date/Time      Lat      Lon    Base\n",
    "    0  4/1/2014 0:11:00  40.7690 -73.9549  B02512\n",
    "    1  4/1/2014 0:17:00  40.7267 -74.0345  B02512\n",
    "    2  4/1/2014 0:21:00  40.7316 -73.9873  B02512\n",
    "    3  4/1/2014 0:28:00  40.7588 -73.9776  B02512\n",
    "    4  4/1/2014 0:33:00  40.7594 -73.9722  B02512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining columns of data\n",
    "\n",
    "Think of column-wise concatenation of data as stitching data together from the sides instead of the top and bottom. To perform this action, you use the same pd.concat() function, but this time with the keyword argument axis=1. The default, axis=0, is for a row-wise concatenation."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Concatenate ebola_melt and status_country column-wise: ebola_tidy\n",
    "ebola_tidy = pd.concat([ebola_melt,status_country], axis=1)\n",
    "\n",
    "# Print the shape of ebola_tidy\n",
    "print(ebola_tidy.shape)\n",
    "\n",
    "# Print the head of ebola_tidy\n",
    "print(ebola_tidy.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "         Date  Day status_country  counts\n",
    "0    1/5/2015  289   Cases_Guinea  2776.0\n",
    "1    1/4/2015  288   Cases_Guinea  2775.0\n",
    "2    1/3/2015  287   Cases_Guinea  2769.0\n",
    "3    1/2/2015  286   Cases_Guinea     NaN\n",
    "4  12/31/2014  284   Cases_Guinea  2730.0\n",
    "  status country\n",
    "0  Cases  Guinea\n",
    "1  Cases  Guinea\n",
    "2  Cases  Guinea\n",
    "3  Cases  Guinea\n",
    "4  Cases  Guinea\n",
    "\n",
    "<script.py> output:\n",
    "    (1952, 6)\n",
    "             Date  Day status_country  counts status country\n",
    "    0    1/5/2015  289   Cases_Guinea  2776.0  Cases  Guinea\n",
    "    1    1/4/2015  288   Cases_Guinea  2775.0  Cases  Guinea\n",
    "    2    1/3/2015  287   Cases_Guinea  2769.0  Cases  Guinea\n",
    "    3    1/2/2015  286   Cases_Guinea     NaN  Cases  Guinea\n",
    "    4  12/31/2014  284   Cases_Guinea  2730.0  Cases  Guinea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding and concatenating data\n",
    "\n",
    "### Concatenating many files\n",
    "- Leverage Pythons features with data cleaning in pandas\n",
    "- In order to concatenate DataFrames:\n",
    " - They must be in a list\n",
    " - Can individually load if there are a few datasets\n",
    " - But what if there are thousands?\n",
    "- Solution: glob function to find files based on a pattern\n",
    "\n",
    "### Globbing\n",
    "- Pa!ern matching for file names\n",
    "- Wildcards: * ?\n",
    " - Any csv file: *.csv\n",
    " - Any single character: file_?.csv\n",
    "- Returns a list of file names\n",
    "- Can use this list to load into separate DataFrames\n",
    "\n",
    "### The plan\n",
    "- Load files from globbing into pandas\n",
    "- Add the DataFrames into a list\n",
    "- Concatenate multiple datasets at once\n",
    "\n",
    "### Finding files that match a pattern\n",
    "\n",
    "Similarly, you can find all .csv files with '*.csv', or all parts with 'part_*'. The ? wildcard represents any 1 character, and the * wildcard represents any number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sampledata.csv', 'sampledata2.csv', 'sampledata3.csv']\n",
      "    ITEM_NO               ITEM_DESC  Logic Packs  Weber Packs  Discrepancies  \\\n",
      "0  44208068       BLANKET, YC (G&G)          461          960            499   \n",
      "1  44207692  REST, CHOPSTICK, ASIAN           14          168            154   \n",
      "2  44206900   BAG, NC HEADSET - RED            0          175            175   \n",
      "3  44207411      TRAY 1/3 ATLAS, YC            0           84             84   \n",
      "4  44207360            AIRSICK BAGS          258          385            127   \n",
      "\n",
      "   Inventory Discrepancy Value  Issue ACTIVE/INACTIVE  \n",
      "0                  $103,695.12    NaN           False  \n",
      "1                   $34,358.02    NaN           False  \n",
      "2                   $25,200.00    NaN           False  \n",
      "3                    $9,220.88    NaN           False  \n",
      "4                    $6,350.00    NaN           False  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Write the pattern: pattern\n",
    "pattern = '*.csv'\n",
    "\n",
    "# Save all file matches: csv_files\n",
    "csv_files = glob.glob(pattern)\n",
    "\n",
    "# Print the file names\n",
    "print(csv_files)\n",
    "\n",
    "# Load the second file into a DataFrame: csv2\n",
    "csv2 = pd.read_csv(csv_files[1])\n",
    "\n",
    "# Print the head of csv2\n",
    "print(csv2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating and concatenating all matches\n",
    "\n",
    "Now that you have a list of filenames to load, you can load all the files into a list of DataFrames that can then be concatenated.\n",
    "\n",
    "You'll start with an empty list called frames. Your job is to use a for loop to iterate through each of the filenames, read each filename into a DataFrame, and then append it to the frames list.\n",
    "\n",
    "You can then concatenate this list of DataFrames using pd.concat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4032, 14)\n",
      "   AMC Item Number   Discrepancy Value   Inventory Discrepancy Value   \\\n",
      "0       L044207509          $25,945.19                            NaN   \n",
      "1       L044207668          $17,813.36                            NaN   \n",
      "2       L044207958          $14,445.00                            NaN   \n",
      "3       L044208068          $94,467.70                            NaN   \n",
      "4       L044207583          $63,712.00                            NaN   \n",
      "\n",
      "  ACTIVE/INACTIVE  Americold Count  Discrepancies  Discrepancy (cases)  \\\n",
      "0           False              NaN            NaN                900.0   \n",
      "1           False              NaN            NaN                540.0   \n",
      "2           False              NaN            NaN                500.0   \n",
      "3           False              NaN            NaN                440.0   \n",
      "4           False              NaN            NaN                362.0   \n",
      "\n",
      "                         ITEM_DESC   ITEM_NO Issue  Logic Count  Logic Packs  \\\n",
      "0  DRAWER, DELTA VARIO ATLAS 120MM  44207509   NaN       1335.0          NaN   \n",
      "1         TOILET PAPER, COTTENELLE  44207668   NaN        445.0          NaN   \n",
      "2         LINER, TRASH CAN, DOM SM  44207958   NaN        259.0          NaN   \n",
      "3                BLANKET, YC (G&G)  44208068   NaN        371.0          NaN   \n",
      "4  FOAMING SOAP, SQUARE M+G 5.4 oz  44207583   NaN        523.0          NaN   \n",
      "\n",
      "   Seafrigo Count  Weber Packs  \n",
      "0          2235.0          NaN  \n",
      "1           985.0          NaN  \n",
      "2           759.0          NaN  \n",
      "3           811.0          NaN  \n",
      "4           885.0          NaN  \n"
     ]
    }
   ],
   "source": [
    "# Create an empty list: frames\n",
    "frames = []\n",
    "\n",
    "#  Iterate over csv_files\n",
    "for csv in csv_files:\n",
    "\n",
    "    #  Read csv into a DataFrame: df\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # Append df to frames\n",
    "    frames.append(df)\n",
    "\n",
    "# Concatenate frames into a single DataFrame: uber\n",
    "uber = pd.concat(frames)\n",
    "\n",
    "# Print the shape of uber\n",
    "print(uber.shape)\n",
    "\n",
    "# Print the head of uber\n",
    "print(uber.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data\n",
    "\n",
    "- Similar to joining tables in SQL\n",
    "- Combine disparate datasets based on common columns\n",
    "\n",
    "### Types of merges\n",
    "\n",
    "- One-to-one\n",
    "- Many-to-one / one-to-many\n",
    "- Many-to-many\n",
    "\n",
    "### Different types of merges\n",
    "\n",
    "- One-to-one\n",
    "- Many-to-one\n",
    "- Many-to-many\n",
    "- All use the same function\n",
    "- Only difference is the DataFrames you are merging\n",
    "\n",
    "### 1-to-1 data merge\n",
    "\n",
    "Merging data allows you to combine disparate datasets into a single dataset to do more complex analysis."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Merge the DataFrames: o2o\n",
    "o2o = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# Print o2o\n",
    "print(o2o)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "        name    lat    long  ident   site       dated\n",
    "    0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
    "    1   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
    "    2  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-1 data merge\n",
    "\n",
    "In a many-to-one (or one-to-many) merge, one of the values will be duplicated and recycled in the output. That is, one of the keys in the merge is not unique.\n",
    "\n",
    "The .merge() method call is the same as the 1-to-1 merge from the previous exercise, but the data and output will be different."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Merge the DataFrames: m2o\n",
    "m2o = pd.merge(left=site,right=visited,left_on='name',right_on='site')\n",
    "\n",
    "# Print m2o\n",
    "print(m2o)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "        name    lat    long  ident   site       dated\n",
    "    0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
    "    1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n",
    "    2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n",
    "    3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
    "    4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n",
    "    5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n",
    "    6   DR-3 -47.15 -126.72    752   DR-3         NaN\n",
    "    7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-many data merge\n",
    "\n",
    "The final merging scenario occurs when both DataFrames do not have unique keys for a merge. What happens here is that for each duplicated key, every pairwise combination will be created.\n",
    "\n",
    "Two example DataFrames that share common key values have been pre-loaded: df1 and df2. Another DataFrame df3, which is the result of df1 merged with df2, has been pre-loaded. All three DataFrames have been printed - look at the output and notice how pairwise combinations have been created. This example is to help you develop your intuition for many-to-many merges."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Merge site and visited: m2m\n",
    "m2m = pd.merge(left=site, right=visited, left_on='name', right_on='site')\n",
    "\n",
    "# Merge m2m and survey: m2m\n",
    "m2m = pd.merge(left=m2m, right=survey, left_on='ident', right_on='taken')\n",
    "\n",
    "# Print the first 20 lines of m2m\n",
    "print(m2m.head(20))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "  c1  c2\n",
    "0  a   1\n",
    "1  a   2\n",
    "2  b   3\n",
    "3  b   4\n",
    "  c1  c2\n",
    "0  a  10\n",
    "1  a  20\n",
    "2  b  30\n",
    "3  b  40\n",
    "  c1  c2_x  c2_y\n",
    "0  a     1    10\n",
    "1  a     1    20\n",
    "2  a     2    10\n",
    "3  a     2    20\n",
    "4  b     3    30\n",
    "5  b     3    40\n",
    "6  b     4    30\n",
    "7  b     4    40\n",
    "\n",
    "<script.py> output:\n",
    "         name    lat    long  ident   site       dated  taken person quant  \\\n",
    "    0    DR-1 -49.85 -128.57    619   DR-1  1927-02-08    619   dyer   rad   \n",
    "    1    DR-1 -49.85 -128.57    619   DR-1  1927-02-08    619   dyer   sal   \n",
    "    2    DR-1 -49.85 -128.57    622   DR-1  1927-02-10    622   dyer   rad   \n",
    "    3    DR-1 -49.85 -128.57    622   DR-1  1927-02-10    622   dyer   sal   \n",
    "    4    DR-1 -49.85 -128.57    844   DR-1  1932-03-22    844    roe   rad   \n",
    "    5    DR-3 -47.15 -126.72    734   DR-3  1939-01-07    734     pb   rad   \n",
    "    6    DR-3 -47.15 -126.72    734   DR-3  1939-01-07    734   lake   sal   \n",
    "    7    DR-3 -47.15 -126.72    734   DR-3  1939-01-07    734     pb  temp   \n",
    "    8    DR-3 -47.15 -126.72    735   DR-3  1930-01-12    735     pb   rad   \n",
    "    9    DR-3 -47.15 -126.72    735   DR-3  1930-01-12    735    NaN   sal   \n",
    "    10   DR-3 -47.15 -126.72    735   DR-3  1930-01-12    735    NaN  temp   \n",
    "    11   DR-3 -47.15 -126.72    751   DR-3  1930-02-26    751     pb   rad   \n",
    "    12   DR-3 -47.15 -126.72    751   DR-3  1930-02-26    751     pb  temp   \n",
    "    13   DR-3 -47.15 -126.72    751   DR-3  1930-02-26    751   lake   sal   \n",
    "    14   DR-3 -47.15 -126.72    752   DR-3         NaN    752   lake   rad   \n",
    "    15   DR-3 -47.15 -126.72    752   DR-3         NaN    752   lake   sal   \n",
    "    16   DR-3 -47.15 -126.72    752   DR-3         NaN    752   lake  temp   \n",
    "    17   DR-3 -47.15 -126.72    752   DR-3         NaN    752    roe   sal   \n",
    "    18  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14    837   lake   rad   \n",
    "    19  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14    837   lake   sal   \n",
    "    \n",
    "        reading  \n",
    "    0      9.82  \n",
    "    1      0.13  \n",
    "    2      7.80  \n",
    "    3      0.09  \n",
    "    4     11.25  \n",
    "    5      8.41  \n",
    "    6      0.05  \n",
    "    7    -21.50  \n",
    "    8      7.22  \n",
    "    9      0.06  \n",
    "    10   -26.00  \n",
    "    11     4.35  \n",
    "    12   -18.50  \n",
    "    13     0.10  \n",
    "    14     2.19  \n",
    "    15     0.09  \n",
    "    16   -16.00  \n",
    "    17    41.60  \n",
    "    18     1.46  \n",
    "    19     0.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types\n",
    "\n",
    "- There may be times we want to convert from one type to another\n",
    " - Numeric columns can be strings, or vice versa\n",
    " \n",
    "### Categorical data\n",
    "- Converting categorical data to category dtype:\n",
    " - Can make the DataFrame smaller in memory\n",
    " - Can make them be utilized by other Python libraries for analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Converting data types"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Convert the sex column to type 'category'\n",
    "tips.sex = tips.sex.astype('category')\n",
    "\n",
    "# Convert the smoker column to type 'category'\n",
    "tips.smoker = tips.smoker.astype('category')\n",
    "\n",
    "# Print the info of tips\n",
    "print(tips.info())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    RangeIndex: 244 entries, 0 to 243\n",
    "    Data columns (total 7 columns):\n",
    "    total_bill    244 non-null float64\n",
    "    tip           244 non-null float64\n",
    "    sex           244 non-null category\n",
    "    smoker        244 non-null category\n",
    "    day           244 non-null object\n",
    "    time          244 non-null object\n",
    "    size          244 non-null int64\n",
    "    dtypes: category(2), float64(2), int64(1), object(2)\n",
    "    memory usage: 10.1+ KB\n",
    "    None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with numeric data\n",
    "\n",
    "If you expect the data type of a column to be numeric (int or float), but instead it is of type object, this typically means that there is a non numeric value in the column, which also signifies bad data.\n",
    "\n",
    "You can use the pd.to_numeric() function to convert a column into a numeric data type. If the function raises an error, you can be sure that there is a bad value within the column. You can either use the techniques you learned in Chapter 1 to do some exploratory data analysis and find the bad value, or you can choose to ignore or coerce the value into a missing value, NaN."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Convert 'total_bill' to a numeric dtype\n",
    "tips['total_bill'] = pd.to_numeric(tips['total_bill'], errors='coerce')\n",
    "\n",
    "# Convert 'tip' to a numeric dtype\n",
    "tips['tip'] = pd.to_numeric(tips['tip'], errors='coerce')\n",
    "\n",
    "# Print the info of tips\n",
    "print(tips.info())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    RangeIndex: 244 entries, 0 to 243\n",
    "    Data columns (total 7 columns):\n",
    "    total_bill    202 non-null float64\n",
    "    tip           220 non-null float64\n",
    "    sex           234 non-null category\n",
    "    smoker        229 non-null category\n",
    "    day           243 non-null category\n",
    "    time          227 non-null category\n",
    "    size          231 non-null float64\n",
    "    dtypes: category(4), float64(3)\n",
    "    memory usage: 6.9 KB\n",
    "    None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using regular expressions to clean strings\n",
    "\n",
    "### String manipulation\n",
    "- Much of data cleaning involves string manipulation \n",
    " - Most of the worlds data is unstructured text\n",
    "- Also have to do string manipulation to make datasets consistent with one another\n",
    "\n",
    "### String manipulation\n",
    "- Many built-in and external libraries \n",
    "- re library for regular expressions\n",
    " - A formal way of specifying a pa ern\n",
    " - Sequence of characters Pa ern matching\n",
    "- Similar to globbing   \n",
    "\n",
    "### Using regular expressions\n",
    "- Compile the pattern\n",
    "- Use the compiled pattern to match values\n",
    "- This lets us use the pattern over and over again\n",
    "- Useful since we want to match values down a column of values\n",
    "\n",
    "### String parsing with regular expressions\n",
    "\n",
    "When working with data, it is sometimes necessary to write a regular expression to look for properly entered values. Phone numbers in a dataset is a common field that needs to be checked for validity. Your job in this exercise is to define a regular expression to match US phone numbers that fit the pattern of xxx-xxx-xxxx.\n",
    "\n",
    "The regular expression module in python is re. When performing pattern matching on data, since the pattern will be used for a match across multiple rows, it's better to compile the pattern first using re.compile(), and then use the compiled pattern to match values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Import the regular expression module\n",
    "import re\n",
    "\n",
    "# Compile the pattern: prog\n",
    "prog = re.compile('\\d{3}-\\d{3}-\\d{4}')\n",
    "\n",
    "# See if the pattern matches\n",
    "result = prog.match('123-456-7890')\n",
    "print(bool(result))\n",
    "\n",
    "# See if the pattern matches\n",
    "result = prog.match('1123-456-7890')\n",
    "print(bool(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting numerical values from strings\n",
    "\n",
    "Extracting numbers from strings is a common task, particularly when working with unstructured data or log files.\n",
    "\n",
    "Say you have the following string: 'the recipe calls for 6 strawberries and 2 bananas'.\n",
    "\n",
    "It would be useful to extract the 6 and the 2 from this string to be saved for later use when comparing strawberry to banana ratios.\n",
    "\n",
    "When using a regular expression to extract multiple numbers (or multiple pattern matches, to be exact), you can use the re.findall() function. Dan did not discuss this in the video, but it is straightforward to use: You pass in a pattern and a string to re.findall(), and it will return a list of the matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '1']\n"
     ]
    }
   ],
   "source": [
    "# Import the regular expression module\n",
    "import re\n",
    "\n",
    "# Find the numeric values: matches\n",
    "matches = re.findall('\\d+', 'the recipe calls for 10 strawberries and 1 banana')\n",
    "\n",
    "# Print the matches\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern matching\n",
    "\n",
    "write the appropriate pattern to match it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Write the first pattern\n",
    "pattern1 = bool(re.match(pattern='\\d{3}-\\d{3}-\\d{4}', string='123-456-7890'))\n",
    "print(pattern1)\n",
    "\n",
    "# Write the second pattern\n",
    "pattern2 = bool(re.match(pattern='\\$\\d*\\d{2}', string='$123.45'))\n",
    "print(pattern2)\n",
    "\n",
    "# Write the third pattern\n",
    "pattern3 = bool(re.match(pattern='[A-Z]\\w*', string='Australia'))\n",
    "print(pattern3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using functions to clean data\n",
    "\n",
    "### Complex cleaning\n",
    "- Cleaning step requires multiple steps \n",
    " - Extract number from string\n",
    " - Perform transformation on extracted number \n",
    "- Python function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom functions to clean data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define recode_sex()\n",
    "def recode_sex(sex_value):\n",
    "\n",
    "    # Return 1 if sex_value is 'Male'\n",
    "    if sex_value == 'Male':\n",
    "        return 1\n",
    "    \n",
    "    # Return 0 if sex_value is 'Female'    \n",
    "    elif sex_value == 'Female':\n",
    "        return 0\n",
    "    \n",
    "    # Return np.nan    \n",
    "    else:\n",
    "        return np.nan \n",
    "\n",
    "# Apply the function to the sex column\n",
    "tips['sex_recode'] = tips.sex.apply(recode_sex)\n",
    "\n",
    "# Print the first five rows of tips\n",
    "print(tips.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "       total_bill   tip     sex smoker  day    time  size  sex_recode\n",
    "    0       16.99  1.01  Female     No  Sun  Dinner   2.0         0.0\n",
    "    1       10.34  1.66    Male     No  Sun  Dinner   3.0         1.0\n",
    "    2       21.01  3.50    Male     No  Sun  Dinner   3.0         1.0\n",
    "    3       23.68  3.31    Male     No  Sun  Dinner   2.0         1.0\n",
    "    4       24.59  3.61  Female     No  Sun  Dinner   4.0         0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda functions\n",
    "\n",
    "Instead of using the def syntax that you used in the previous exercise, lambda functions let you make simple, one-line functions.\n",
    "\n",
    "For example, here's a function that squares a variable used in an .apply() method:\n",
    "\n",
    "def my_square(x):\n",
    "    return x ** 2\n",
    "\n",
    "df.apply(my_square)\n",
    "\n",
    "The equivalent code using a lambda function is:\n",
    "\n",
    "df.apply(lambda x: x ** 2)\n",
    "\n",
    "The lambda function takes one parameter - the variable x. The function itself just squares x and returns the result, which is whatever the one line of code evaluates to. In this way, lambda functions can make your code concise and Pythonic."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write the lambda function using replace\n",
    "tips['total_dollar_replace'] = tips['total_dollar'].apply(lambda x: x.replace('$', ''))\n",
    "\n",
    "# Write the lambda function using regular expressions\n",
    "tips['total_dollar_re'] = tips['total_dollar'].apply(lambda x: re.findall('\\d+\\.\\d+', x)[0])\n",
    "\n",
    "# Print the head of tips\n",
    "print(tips.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "       total_bill   tip     sex smoker  day    time  size total_dollar  \\\n",
    "    0       16.99  1.01  Female     No  Sun  Dinner     2       $16.99   \n",
    "    1       10.34  1.66    Male     No  Sun  Dinner     3       $10.34   \n",
    "    2       21.01  3.50    Male     No  Sun  Dinner     3       $21.01   \n",
    "    3       23.68  3.31    Male     No  Sun  Dinner     2       $23.68   \n",
    "    4       24.59  3.61  Female     No  Sun  Dinner     4       $24.59   \n",
    "    \n",
    "      total_dollar_replace total_dollar_re  \n",
    "    0                16.99           16.99  \n",
    "    1                10.34           10.34  \n",
    "    2                21.01           21.01  \n",
    "    3                23.68           23.68  \n",
    "    4                24.59           24.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate and missing data\n",
    "\n",
    "- Can skew results \n",
    "- .drop_duplicates() method\n",
    "\n",
    "### Fill missing values with .fillna()\n",
    "- Fill with provided value \n",
    "- Use a summary statistic\n",
    "\n",
    "### Fill missing values with a test statistic\n",
    "- Careful when using test statistics to fill\n",
    "- Have to make sure the value you are filling in makes sense \n",
    "- Median is a be er statistic in the presence of outliers\n",
    "\n",
    "### Dropping duplicate data\n",
    "\n",
    "Duplicate data causes a variety of problems. From the point of view of performance, they use up unnecessary amounts of memory and cause unneeded calculations to be performed when processing data. In addition, they can also bias any analysis results."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create the new DataFrame: tracks\n",
    "tracks = billboard[['year','artist','track','time']]\n",
    "\n",
    "# Print info of tracks\n",
    "print(tracks.info())\n",
    "\n",
    "# Drop the duplicates: tracks_no_duplicates\n",
    "tracks_no_duplicates = tracks.drop_duplicates()\n",
    "\n",
    "# Print info of tracks\n",
    "print(tracks_no_duplicates.info())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    RangeIndex: 24092 entries, 0 to 24091\n",
    "    Data columns (total 4 columns):\n",
    "    year      24092 non-null int64\n",
    "    artist    24092 non-null object\n",
    "    track     24092 non-null object\n",
    "    time      24092 non-null object\n",
    "    dtypes: int64(1), object(3)\n",
    "    memory usage: 753.0+ KB\n",
    "    None\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    Int64Index: 317 entries, 0 to 316\n",
    "    Data columns (total 4 columns):\n",
    "    year      317 non-null int64\n",
    "    artist    317 non-null object\n",
    "    track     317 non-null object\n",
    "    time      317 non-null object\n",
    "    dtypes: int64(1), object(3)\n",
    "    memory usage: 12.4+ KB\n",
    "    None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Calculate the mean of the Ozone column: oz_mean\n",
    "oz_mean = airquality['Ozone'].mean()\n",
    "\n",
    "# Replace all the missing values in the Ozone column with the mean\n",
    "airquality['Ozone'] = airquality.Ozone.fillna(oz_mean)\n",
    "\n",
    "# Print the info of airquality\n",
    "print(airquality.info())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    RangeIndex: 153 entries, 0 to 152\n",
    "    Data columns (total 6 columns):\n",
    "    Ozone      153 non-null float64\n",
    "    Solar.R    146 non-null float64\n",
    "    Wind       153 non-null float64\n",
    "    Temp       153 non-null int64\n",
    "    Month      153 non-null int64\n",
    "    Day        153 non-null int64\n",
    "    dtypes: float64(3), int64(3)\n",
    "    memory usage: 7.2 KB\n",
    "    None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with asserts\n",
    "\n",
    "### Assert statements\n",
    "- Programmatically vs visually checking\n",
    "- If we drop or fill NaNs, we expect 0 missing values \n",
    "- We can write an assert statement to verify this \n",
    "- We can detect early warnings and errors\n",
    "- This gives us confidence that our code is running correctly\n",
    "\n",
    "### Testing your data with asserts\n",
    "\n",
    "use the .all() method together with the .notnull() DataFrame method to check for missing values in a column. The .all() method returns True if all values are True. When used on a DataFrame, it returns a Series of Booleans - one for each column in the DataFrame. So if you are using it on a DataFrame, like in this exercise, you need to chain another .all() method so that you return only one True or False value. When using these within an assert statement, nothing will be returned if the assert statement is true: This is how you can confirm that the data you are checking are valid.\n",
    "\n",
    "Note: You can use pd.notnull(df) as an alternative to df.notnull()."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Assert that there are no missing values\n",
    "assert pd.notnull(ebola).all().all()\n",
    "\n",
    "# Assert that all values are >= 0\n",
    "assert (ebola >= 0).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "\n",
    "- Load and view data in pandas\n",
    "- Visually inspect data for errors and potential problems\n",
    "- Tidy data for analysis and reshape it\n",
    "- Combine datasets\n",
    "- Clean data by using regular expressions and functions\n",
    "- Test your data and be proactive in finding potential errors\n",
    "\n",
    "### Combining data\n",
    "- pd.merge(df1, df2, ...) \n",
    "- pd.concat([df1, df2, df3, ...])\n",
    "\n",
    "## Initial impressions of the data\n",
    "\n",
    "### Principles of tidy data\n",
    "- Rows form observations\n",
    "- Columns form variables\n",
    "- Tidying data will make data cleaning easier \n",
    "- Melting turns columns into rows\n",
    "- Pivot will take unique values from a column and create new columns\n",
    "\n",
    "### Exploratory analysis\n",
    "\n",
    "Whenever you obtain a new dataset, your first task should always be to do some exploratory analysis to get a better understanding of the data and diagnose it for any potential issues.\n",
    "\n",
    "The Gapminder data for the 19th century has been loaded into a DataFrame called g1800s. In the IPython Shell, use pandas methods such as .head(), .info(), and .describe(), and DataFrame attributes like .columns and .shape to explore it.\n",
    "\n",
    "### Visualizing your data\n",
    "\n",
    "### Thinking about the question at hand\n",
    "\n",
    "Since you are given life expectancy level data by country and year, you could ask questions about how much the average life expectancy changes over each year.\n",
    "\n",
    "Before continuing, however, it's important to make sure that the following assumptions about the data are true:\n",
    "\n",
    "'Life expectancy' is the first column (index 0) of the DataFrame.\n",
    "The other columns contain either null or numeric values.\n",
    "The numeric values are all greater than or equal to 0.\n",
    "There is only one instance of each country.\n",
    "You can write a function that you can apply over the entire DataFrame to verify some of these assumptions. Note that spending the time to write such a script will help you when working with other datasets as well."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def check_null_or_valid(row_data):\n",
    "    \"\"\"Function that takes a row of data,\n",
    "    drops all missing values,\n",
    "    and checks if all remaining values are greater than or equal to 0\n",
    "    \"\"\"\n",
    "    no_na = row_data.dropna()[1:-1]\n",
    "    numeric = pd.to_numeric(no_na)\n",
    "    ge0 = numeric >= 0\n",
    "    return ge0\n",
    "\n",
    "# Check whether the first column is 'Life expectancy'\n",
    "assert g1800s.columns[0] == 'Life expectancy'\n",
    "\n",
    "# Check whether the values in the row are valid\n",
    "assert g1800s.iloc[:, 1:].apply(check_null_or_valid, axis=1).all().all()\n",
    "\n",
    "# Check that there is only one instance of each country\n",
    "assert g1800s['Life expectancy'].value_counts()[0] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling your data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Concatenate the DataFrames row-wise\n",
    "gapminder = pd.concat([g1800s,g1900s,g2000s])\n",
    "\n",
    "# Print the shape of gapminder\n",
    "print(gapminder.shape)\n",
    "\n",
    "# Print the head of gapminder\n",
    "print(gapminder.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    (780, 218)\n",
    "        1800   1801   1802   1803   1804   1805   1806   1807   1808   1809  \\\n",
    "    0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
    "    1  28.21  28.20  28.19  28.18  28.17  28.16  28.15  28.14  28.13  28.12   \n",
    "    2    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
    "    3  35.40  35.40  35.40  35.40  35.40  35.40  35.40  35.40  35.40  35.40   \n",
    "    4  28.82  28.82  28.82  28.82  28.82  28.82  28.82  28.82  28.82  28.82   \n",
    "    \n",
    "               ...            2008  2009  2010  2011  2012  2013  2014  2015  \\\n",
    "    0          ...             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
    "    1          ...             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
    "    2          ...             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
    "    3          ...             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
    "    4          ...             NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
    "    \n",
    "       2016        Life expectancy  \n",
    "    0   NaN               Abkhazia  \n",
    "    1   NaN            Afghanistan  \n",
    "    2   NaN  Akrotiri and Dhekelia  \n",
    "    3   NaN                Albania  \n",
    "    4   NaN                Algeria  \n",
    "    \n",
    "    [5 rows x 218 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping your data\n",
    "\n",
    "Now that you have all the data combined into a single DataFrame, the next step is to reshape it into a tidy data format."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Melt gapminder: gapminder_melt\n",
    "gapminder_melt = pd.melt(gapminder,id_vars='Life expectancy')\n",
    "\n",
    "# Rename the columns\n",
    "gapminder_melt.columns = ['country','year','life_expectancy']\n",
    "\n",
    "# Print the head of gapminder_melt\n",
    "print(gapminder_melt.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "                     country  year  life_expectancy\n",
    "    0               Abkhazia  1800              NaN\n",
    "    1            Afghanistan  1800            28.21\n",
    "    2  Akrotiri and Dhekelia  1800              NaN\n",
    "    3                Albania  1800            35.40\n",
    "    4                Algeria  1800            28.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the data types"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Convert the year column to numeric\n",
    "gapminder.year = pd.to_numeric(gapminder.year)\n",
    "\n",
    "# Test if country is of type object\n",
    "assert gapminder.country.dtypes == np.object\n",
    "\n",
    "# Test if year is of type int64\n",
    "assert gapminder.year.dtypes==np.int64\n",
    "\n",
    "# Test if life_expectancy is of type float64\n",
    "assert gapminder.life_expectancy.dtypes == np.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at country spellings\n",
    "\n",
    "Having tidied your DataFrame and checked the data types, your next task in the data cleaning process is to look at the 'country' column to see if there are any special or invalid characters you may need to deal with.\n",
    "\n",
    "It is reasonable to assume that country names will contain:\n",
    "\n",
    "The set of lower and upper case letters.\n",
    "Whitespace between words.\n",
    "Periods for any abbreviations.\n",
    "To confirm that this is the case, you can leverage the power of regular expressions again. For common operations like this, Python has a built-in string method - str.contains() - which takes a regular expression pattern, and applies it to the Series, returning True if there is a match, and False otherwise.\n",
    "\n",
    "Since here you want to find the values that do not match, you have to invert the boolean, which can be done using ~. This Boolean series can then be used to get the Series of countries that have invalid names"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create the series of countries: countries\n",
    "countries = gapminder['country']\n",
    "\n",
    "# Drop all the duplicates from countries\n",
    "countries = countries.drop_duplicates()\n",
    "\n",
    "# Write the regular expression: pattern\n",
    "pattern = '^[A-Za-z\\.\\s]*$'\n",
    "\n",
    "# Create the Boolean vector: mask\n",
    "mask = countries.str.contains(pattern)\n",
    "\n",
    "# Invert the mask: mask_inverse\n",
    "mask_inverse = ~mask\n",
    "\n",
    "# Subset countries using mask_inverse: invalid_countries\n",
    "invalid_countries = countries.loc[mask_inverse]\n",
    "\n",
    "# Print invalid_countries\n",
    "print(invalid_countries)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    49            Congo, Dem. Rep.\n",
    "    50                 Congo, Rep.\n",
    "    53               Cote d'Ivoire\n",
    "    73      Falkland Is (Malvinas)\n",
    "    93               Guinea-Bissau\n",
    "    98            Hong Kong, China\n",
    "    118    United Korea (former)\\n\n",
    "    131               Macao, China\n",
    "    132             Macedonia, FYR\n",
    "    145      Micronesia, Fed. Sts.\n",
    "    161            Ngorno-Karabakh\n",
    "    187             St. Barthlemy\n",
    "    193     St.-Pierre-et-Miquelon\n",
    "    225                Timor-Leste\n",
    "    251      Virgin Islands (U.S.)\n",
    "    252       North Yemen (former)\n",
    "    253       South Yemen (former)\n",
    "    258                      land\n",
    "    Name: country, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More data cleaning and processing\n",
    "\n",
    "It's now time to deal with the missing data. There are several strategies for this: You can drop them, fill them in using the mean of the column or row that the missing value is in (also known as imputation), or, if you are dealing with time series data, use a forward fill or backward fill, in which you replace missing values in a column with the most recent known value in the column. See pandas Foundations for more on forward fill and backward fill.\n",
    "\n",
    "In general, it is not the best idea to drop missing values, because in doing so you may end up throwing away useful information. In this data, the missing values refer to years where no estimate for life expectancy is available for a given country. You could fill in, or guess what these life expectancies could be by looking at the average life expectancies for other countries in that year, for example. Whichever strategy you go with, it is important to carefully consider all options and understand how they will affect your data."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Assert that country does not contain any missing values\n",
    "assert pd.notnull(gapminder.country).all()\n",
    "\n",
    "# Assert that year does not contain any missing values\n",
    "assert pd.notnull(gapminder.year).all()\n",
    "\n",
    "# Drop the missing values\n",
    "gapminder = gapminder.dropna(axis=0,how='any')\n",
    "\n",
    "# Print the shape of gapminder\n",
    "print(gapminder.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    (43857, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping up\n",
    "\n",
    "Now that you have a clean and tidy dataset, you can do a bit of visualization and aggregation\n",
    "\n",
    "To investigate how average life expectancy changed over the years. You need to subset the data by each year, get the life_expectancy column from each subset, and take an average of the values. You can achieve this using the .groupby() method.\n",
    "\n",
    "Finally, you can save your tidy and summarized DataFrame to a file using the .to_csv() method."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Add first subplot\n",
    "plt.subplot(2, 1, 1) \n",
    "\n",
    "# Create a histogram of life_expectancy\n",
    "gapminder.life_expectancy.plot(kind='hist')\n",
    "\n",
    "# Group gapminder: gapminder_agg\n",
    "gapminder_agg = gapminder.groupby('year')['life_expectancy'].mean()\n",
    "\n",
    "# Print the head of gapminder_agg\n",
    "print(gapminder_agg.head())\n",
    "\n",
    "# Print the tail of gapminder_agg\n",
    "print(gapminder_agg.tail())\n",
    "\n",
    "# Add second subplot\n",
    "plt.subplot(2, 1, 2)\n",
    "\n",
    "# Create a line plot of life expectancy per year\n",
    "gapminder_agg.plot()\n",
    "\n",
    "# Add title and specify axis labels\n",
    "plt.title('Life expectancy over the years')\n",
    "plt.ylabel('Life expectancy')\n",
    "plt.xlabel('Year')\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save both DataFrames to csv files\n",
    "gapminder.to_csv('gapminder.csv')\n",
    "gapminder_agg.to_csv('gapminder_agg.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    year\n",
    "    1800    31.486020\n",
    "    1801    31.448905\n",
    "    1802    31.463483\n",
    "    1803    31.377413\n",
    "    1804    31.446318\n",
    "    Name: life_expectancy, dtype: float64\n",
    "    year\n",
    "    2012    71.663077\n",
    "    2013    71.916106\n",
    "    2014    72.088125\n",
    "    2015    72.321010\n",
    "    2016    72.556635\n",
    "    Name: life_expectancy, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
