{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating DataFrames with pandas\n",
    "\n",
    "- Extracting, filtering, and transforming data from DataFrames\n",
    "- Advanced indexing with multiple levels\n",
    "- Tidying, rearranging and restructuring your data\n",
    "- Pivoting, melting, and stacking DataFrames\n",
    "- Identifying and spli!ing DataFrames by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_NO</th>\n",
       "      <th>AMC Item Number</th>\n",
       "      <th>ITEM_DESC</th>\n",
       "      <th>Logic Count</th>\n",
       "      <th>Seafrigo Count</th>\n",
       "      <th>Discrepancy (cases)</th>\n",
       "      <th>Discrepancy Value</th>\n",
       "      <th>ACTIVE/INACTIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44207509</td>\n",
       "      <td>L044207509</td>\n",
       "      <td>DRAWER, DELTA VARIO ATLAS 120MM</td>\n",
       "      <td>1335</td>\n",
       "      <td>2235</td>\n",
       "      <td>900</td>\n",
       "      <td>$25,945.19</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44207668</td>\n",
       "      <td>L044207668</td>\n",
       "      <td>TOILET PAPER, COTTENELLE</td>\n",
       "      <td>445</td>\n",
       "      <td>985</td>\n",
       "      <td>540</td>\n",
       "      <td>$17,813.36</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44207958</td>\n",
       "      <td>L044207958</td>\n",
       "      <td>LINER, TRASH CAN, DOM SM</td>\n",
       "      <td>259</td>\n",
       "      <td>759</td>\n",
       "      <td>500</td>\n",
       "      <td>$14,445.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44208068</td>\n",
       "      <td>L044208068</td>\n",
       "      <td>BLANKET, YC (G&amp;G)</td>\n",
       "      <td>371</td>\n",
       "      <td>811</td>\n",
       "      <td>440</td>\n",
       "      <td>$94,467.70</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44207583</td>\n",
       "      <td>L044207583</td>\n",
       "      <td>FOAMING SOAP, SQUARE M+G 5.4 oz</td>\n",
       "      <td>523</td>\n",
       "      <td>885</td>\n",
       "      <td>362</td>\n",
       "      <td>$63,712.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ITEM_NO  AMC Item Number                         ITEM_DESC  Logic Count  \\\n",
       "0  44207509       L044207509   DRAWER, DELTA VARIO ATLAS 120MM         1335   \n",
       "1  44207668       L044207668          TOILET PAPER, COTTENELLE          445   \n",
       "2  44207958       L044207958          LINER, TRASH CAN, DOM SM          259   \n",
       "3  44208068       L044208068                 BLANKET, YC (G&G)          371   \n",
       "4  44207583       L044207583   FOAMING SOAP, SQUARE M+G 5.4 oz          523   \n",
       "\n",
       "   Seafrigo Count  Discrepancy (cases)  Discrepancy Value  ACTIVE/INACTIVE  \n",
       "0            2235                  900         $25,945.19            False  \n",
       "1             985                  540         $17,813.36            False  \n",
       "2             759                  500         $14,445.00            False  \n",
       "3             811                  440         $94,467.70            False  \n",
       "4             885                  362         $63,712.00            False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sampledata.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ITEM_NO', u' AMC Item Number ', u'ITEM_DESC', u'Logic Count',\n",
       "       u'Seafrigo Count', u'Discrepancy (cases)', u' Discrepancy Value ',\n",
       "       u'ACTIVE/INACTIVE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'44207668'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1, 'ITEM_NO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional and labeled indexing\n",
    "\n",
    "Given a pair of label-based indices, sometimes it's necessary to find the corresponding positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and column rearrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                ITEM_DESC  Logic Count  Seafrigo Count\n",
      "ITEM_NO                                                               \n",
      "44207509  DRAWER, DELTA VARIO ATLAS 120MM         1335            2235\n",
      "44207668         TOILET PAPER, COTTENELLE          445             985\n",
      "44207958         LINER, TRASH CAN, DOM SM          259             759\n",
      "44208068                BLANKET, YC (G&G)          371             811\n",
      "44207583  FOAMING SOAP, SQUARE M+G 5.4 oz          523             885\n"
     ]
    }
   ],
   "source": [
    "# Read in filename and set the index: election\n",
    "election = pd.read_csv('sampledata.csv', index_col='ITEM_NO')\n",
    "\n",
    "# Create a separate dataframe with the columns ['winner', 'total', 'voters']: results\n",
    "results = pd.DataFrame(election, columns=['ITEM_DESC', 'Logic Count', 'Seafrigo Count'])\n",
    "\n",
    "# Print the output of results.head()\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          AMC Item Number                         ITEM_DESC  Logic Count  \\\n",
      "ITEM_NO                                                                    \n",
      "44207509       L044207509   DRAWER, DELTA VARIO ATLAS 120MM         1335   \n",
      "44207668       L044207668          TOILET PAPER, COTTENELLE          445   \n",
      "44207958       L044207958          LINER, TRASH CAN, DOM SM          259   \n",
      "44208068       L044208068                 BLANKET, YC (G&G)          371   \n",
      "\n",
      "          Seafrigo Count  Discrepancy (cases)  Discrepancy Value   \\\n",
      "ITEM_NO                                                             \n",
      "44207509            2235                  900         $25,945.19    \n",
      "44207668             985                  540         $17,813.36    \n",
      "44207958             759                  500         $14,445.00    \n",
      "44208068             811                  440         $94,467.70    \n",
      "\n",
      "         ACTIVE/INACTIVE  \n",
      "ITEM_NO                   \n",
      "44207509           False  \n",
      "44207668           False  \n",
      "44207958           False  \n",
      "44208068           False  \n",
      "          AMC Item Number                         ITEM_DESC  Logic Count  \\\n",
      "ITEM_NO                                                                    \n",
      "44208068       L044208068                 BLANKET, YC (G&G)          371   \n",
      "44207958       L044207958          LINER, TRASH CAN, DOM SM          259   \n",
      "44207668       L044207668          TOILET PAPER, COTTENELLE          445   \n",
      "44207509       L044207509   DRAWER, DELTA VARIO ATLAS 120MM         1335   \n",
      "\n",
      "          Seafrigo Count  Discrepancy (cases)  Discrepancy Value   \\\n",
      "ITEM_NO                                                             \n",
      "44208068             811                  440         $94,467.70    \n",
      "44207958             759                  500         $14,445.00    \n",
      "44207668             985                  540         $17,813.36    \n",
      "44207509            2235                  900         $25,945.19    \n",
      "\n",
      "         ACTIVE/INACTIVE  \n",
      "ITEM_NO                   \n",
      "44208068           False  \n",
      "44207958           False  \n",
      "44207668           False  \n",
      "44207509           False  \n"
     ]
    }
   ],
   "source": [
    "# Slice the row labels 'Perry' to 'Potter': p_counties\n",
    "p_counties = election.loc['44207509':'44208068':]\n",
    "\n",
    "# Print the p_counties DataFrame\n",
    "print(p_counties)\n",
    "\n",
    "# Slice the row labels 'Potter' to 'Perry' in reverse order: p_counties_rev\n",
    "p_counties_rev = election.loc['44208068':'44207509':-1]\n",
    "\n",
    "# Print the p_counties_rev DataFrame\n",
    "print(p_counties_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          AMC Item Number                         ITEM_DESC  Logic Count  \\\n",
      "ITEM_NO                                                                    \n",
      "44207509       L044207509   DRAWER, DELTA VARIO ATLAS 120MM         1335   \n",
      "44207668       L044207668          TOILET PAPER, COTTENELLE          445   \n",
      "44207958       L044207958          LINER, TRASH CAN, DOM SM          259   \n",
      "44208068       L044208068                 BLANKET, YC (G&G)          371   \n",
      "44207583       L044207583   FOAMING SOAP, SQUARE M+G 5.4 oz          523   \n",
      "\n",
      "          Seafrigo Count  \n",
      "ITEM_NO                   \n",
      "44207509            2235  \n",
      "44207668             985  \n",
      "44207958             759  \n",
      "44208068             811  \n",
      "44207583             885  \n",
      "          Logic Count  Seafrigo Count\n",
      "ITEM_NO                              \n",
      "44207509         1335            2235\n",
      "44207668          445             985\n",
      "44207958          259             759\n",
      "44208068          371             811\n",
      "44207583          523             885\n",
      "          Logic Count  Seafrigo Count  Discrepancy (cases)  \\\n",
      "ITEM_NO                                                      \n",
      "44207509         1335            2235                  900   \n",
      "44207668          445             985                  540   \n",
      "44207958          259             759                  500   \n",
      "44208068          371             811                  440   \n",
      "44207583          523             885                  362   \n",
      "\n",
      "          Discrepancy Value  ACTIVE/INACTIVE  \n",
      "ITEM_NO                                       \n",
      "44207509         $25,945.19            False  \n",
      "44207668         $17,813.36            False  \n",
      "44207958         $14,445.00            False  \n",
      "44208068         $94,467.70            False  \n",
      "44207583         $63,712.00            False  \n"
     ]
    }
   ],
   "source": [
    "# Slice the columns from the starting column to 'Obama': left_columns\n",
    "left_columns = election.loc[:,:'Seafrigo Count']\n",
    "\n",
    "# Print the output of left_columns.head()\n",
    "print(left_columns.head(5))\n",
    "\n",
    "# Slice the columns from 'Obama' to 'winner': middle_columns\n",
    "middle_columns = election.loc[:,'Logic Count':'Seafrigo Count']\n",
    "\n",
    "# Print the output of middle_columns.head()\n",
    "print(middle_columns.head(5))\n",
    "\n",
    "# Slice the columns from 'Romney' to the end: 'right_columns'\n",
    "right_columns = election.loc[:,'Logic Count':]\n",
    "\n",
    "# Print the output of right_columns.head()\n",
    "print(right_columns.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subselecting DataFrames with lists\n",
    "\n",
    "You can use lists to select specific row and column labels with the .loc[] accessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Seafrigo Count  Logic Count ACTIVE/INACTIVE\n",
      "ITEM_NO                                              \n",
      "44207583             885          523           False\n",
      "44207668             985          445           False\n",
      "44207958             759          259           False\n"
     ]
    }
   ],
   "source": [
    "# Create the list of row labels: rows\n",
    "rows = ['44207583', '44207668', '44207958']\n",
    "\n",
    "# Create the list of column labels: cols\n",
    "cols = ['Seafrigo Count', 'Logic Count', 'ACTIVE/INACTIVE']\n",
    "\n",
    "# Create the new DataFrame: three_counties\n",
    "three_counties = election.loc[rows,cols]\n",
    "\n",
    "# Print the three_counties DataFrame\n",
    "print(three_counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              AMC Item Number                                 ITEM_DESC  \\\n",
      "ITEM_NO                                                                   \n",
      "44207509           L044207509           DRAWER, DELTA VARIO ATLAS 120MM   \n",
      "44207668           L044207668                  TOILET PAPER, COTTENELLE   \n",
      "44207958           L044207958                  LINER, TRASH CAN, DOM SM   \n",
      "44208068           L044208068                         BLANKET, YC (G&G)   \n",
      "44207583           L044207583           FOAMING SOAP, SQUARE M+G 5.4 oz   \n",
      "44207984           L044207984                             STICK, TRUVIA   \n",
      "44206683           L044206683            TOWEL, CLEANING WIPE (CS ONLY)   \n",
      "44206359           L044206359                ATLAS FULL MEALTRAY, WHITE   \n",
      "44207770           L044207770                          TRAY, ATLAS FULL   \n",
      "44207015           L044207015        SWEETENER, PINK, STIX w/DELTA LOGO   \n",
      "44206821           L044206821           BAG, BLACK SML PLSTC 30x37 1MIL   \n",
      "44207643           L044207643                      TOPPER, CART - PAPER   \n",
      "44206916           L044206916                        LID, FOIL FOR 6915   \n",
      "44204854           L044204854      SEAL, RED PLASTIC HEADSET/LIQUOR KIT   \n",
      "44207959           L044207959                 LINER, TRASH CAN, INTL LG   \n",
      "44207725           L044207725                               GLASS, WINE   \n",
      "44201089           L044201089                  COVER, PAPER TOILET SEAT   \n",
      "44207929           L044207929               CUP, PLASTIC EMBOSSED 11OZ.   \n",
      "44207771           L044207771                           TRAY, ATLAS 2/3   \n",
      "44207520           L044207520                 BASKET, RECTANGULAR FRUIT   \n",
      "044906600-TP    L044906600-TP   WINE, SPARKLING 187ML, LAMARCA PROSECCO   \n",
      "44206162           L044206162                      NAPKIN, SANITARY PAD   \n",
      "44208089           L044208089                         GLASS, ROCKS 8 OZ   \n",
      "44207773           L044207773                          TRAY DL STD FULL   \n",
      "44207778           L044207778                      LID, ASIAN BOWL RICE   \n",
      "44207838           L044207838                                  MITT, BE   \n",
      "44207927           L044207927                      CTO, BEVERAGE SERVER   \n",
      "44207772           L044207772                            TRAY ATLAS 1/2   \n",
      "44207947           L044207947                          BLANKET, FC GREY   \n",
      "44206280           L044206280                            GLASS, MARTINI   \n",
      "...                        ...                                      ...   \n",
      "44208009           L044208009                        MILK CHOC TRUFFLES   \n",
      "44208039           L044208039                         OBERTO BEEF JERKY   \n",
      "44208059           L044208059              RED ICE CREAM SPOON & NAPKIN   \n",
      "44206432           L044206432           BE SQUARE RAMEKIN, LARGE 3-1/8\"   \n",
      "44207038           L044207038                  TRAY, SLOTTED BEV 12-CUP   \n",
      "44207512           L044207512                 BE TEA, ORGANIC GREEN TEA   \n",
      "44207614           L044207614                     LID F.BOWL LARGE 8730   \n",
      "44207669           L044207669                          TOWEL, SCOTTFOLD   \n",
      "44207749           L044207749                           SHAKER, MARTINI   \n",
      "44207923           L044207923                         TRAY, SERVING S/S   \n",
      "44208098           L044208098        TRAY, DOM ECONOMY - BAGASSE - TPPI   \n",
      "44207636           L044207636              BAG, EARBUD RECOVERY 14\"X18\"   \n",
      "44207701           L044207701                               PLATE SMALL   \n",
      "44207960           L044207960                 LINER, TRASH CAN, INTL SM   \n",
      "44206755           L044206755          DIVIDER, 12-SECTION CRA-4201 NWA   \n",
      "44206983           L044206983                            BAG, BE PILLOW   \n",
      "44208036           L044208036     DELTA PREMIUM AMENITY LAUNCH KIT 2017   \n",
      "44207225           L044207225           NAPKIN, LINEN, BEIGE BUTTONHOLE   \n",
      "44207949           L044207949               CUP, PLASTIC EMBOSSED 11OZ.   \n",
      "44208030           L044208030          CHOPSTICKS, JAPANESE AND WRAPPER   \n",
      "44207913           L044207913                     DRAWER, ATLAS ICE CTO   \n",
      "44207922           L044207922                         TRAY, PICK UP S/S   \n",
      "44208000           L044208000                       COVER, CART BE GRAY   \n",
      "44207510           L044207510     LINER, STANDARD ICE THERMOFORMED HDPE   \n",
      "44207708           L044207708                                MUG COFFEE   \n",
      "44207924           L044207924      BASKET, RECT STAINLESS STEEL - LARGE   \n",
      "44207307           L044207307               BLANKET, DELTA HEAVENLY BED   \n",
      "44208035           L044208035                    DELTA ECONOMY KIT 2017   \n",
      "44207439           L044207439                           MARGARITA MIXER   \n",
      "44206947           L044206947                         CUTLERY, PACK 6/1   \n",
      "\n",
      "              Logic Count  Seafrigo Count  Discrepancy (cases)  \\\n",
      "ITEM_NO                                                          \n",
      "44207509             1335            2235                  900   \n",
      "44207668              445             985                  540   \n",
      "44207958              259             759                  500   \n",
      "44208068              371             811                  440   \n",
      "44207583              523             885                  362   \n",
      "44207984               39             327                  288   \n",
      "44206683              718             918                  200   \n",
      "44206359              637             837                  200   \n",
      "44207770              272             462                  190   \n",
      "44207015               61             205                  144   \n",
      "44206821               37             167                  130   \n",
      "44207643               27             147                  120   \n",
      "44206916              281             381                  100   \n",
      "44204854               32             128                   96   \n",
      "44207959              743             837                   94   \n",
      "44207725             4010            4094                   84   \n",
      "44201089              113             193                   80   \n",
      "44207929             6800            6863                   63   \n",
      "44207771               39              99                   60   \n",
      "44207520              131             181                   50   \n",
      "044906600-TP            0              46                   46   \n",
      "44206162              151             191                   40   \n",
      "44208089              240             278                   38   \n",
      "44207773               16              51                   35   \n",
      "44207778               82             108                   26   \n",
      "44207838               26              50                   24   \n",
      "44207927              601             621                   20   \n",
      "44207772                0              17                   17   \n",
      "44207947             1010            1027                   17   \n",
      "44206280                0              12                   12   \n",
      "...                   ...             ...                  ...   \n",
      "44208009                0               0                    0   \n",
      "44208039                0               0                    0   \n",
      "44208059                0               0                    0   \n",
      "44206432               29              28                   -1   \n",
      "44207038              244             243                   -1   \n",
      "44207512              408             407                   -1   \n",
      "44207614               71              70                   -1   \n",
      "44207669             1140            1139                   -1   \n",
      "44207749               89              88                   -1   \n",
      "44207923                1               0                   -1   \n",
      "44208098             1011            1010                   -1   \n",
      "44207636               91              90                   -1   \n",
      "44207701              565             564                   -1   \n",
      "44207960              948             947                   -1   \n",
      "44206755                4               3                   -1   \n",
      "44206983              206             205                   -1   \n",
      "44208036              261             260                   -1   \n",
      "44207225              508             506                   -2   \n",
      "44207949             6815            6813                   -2   \n",
      "44208030               17              15                   -2   \n",
      "44207913              916             913                   -3   \n",
      "44207922               52              48                   -4   \n",
      "44208000              155             151                   -4   \n",
      "44207510              167             162                   -5   \n",
      "44207708             4634            4629                   -5   \n",
      "44207924              286             276                  -10   \n",
      "44207307               54              37                  -17   \n",
      "44208035              763             740                  -23   \n",
      "44207439              206             178                  -28   \n",
      "44206947              917             869                  -48   \n",
      "\n",
      "              Discrepancy Value  ACTIVE/INACTIVE  \n",
      "ITEM_NO                                           \n",
      "44207509             $25,945.19            False  \n",
      "44207668             $17,813.36            False  \n",
      "44207958             $14,445.00            False  \n",
      "44208068             $94,467.70            False  \n",
      "44207583             $63,712.00            False  \n",
      "44207984              $6,912.00            False  \n",
      "44206683              $8,342.05            False  \n",
      "44206359              $5,780.00            False  \n",
      "44207770             $37,972.00            False  \n",
      "44207015              $2,373.86            False  \n",
      "44206821              $1,937.46            False  \n",
      "44207643              $5,886.03            False  \n",
      "44206916              $2,280.00            False  \n",
      "44204854              $2,040.00            False  \n",
      "44207959              $2,565.26            False  \n",
      "44207725              $2,528.06            False  \n",
      "44201089              $2,698.80            False  \n",
      "44207929                $899.01            False  \n",
      "44207771              $9,601.20            False  \n",
      "44207520              $3,036.00            False  \n",
      "044906600-TP          $2,978.50            False  \n",
      "44206162                $887.13            False  \n",
      "44208089              $1,162.80            False  \n",
      "44207773              $6,595.75            False  \n",
      "44207778             $10,882.40            False  \n",
      "44207838              $1,930.75            False  \n",
      "44207927              $2,340.94            False  \n",
      "44207772              $3,728.10            False  \n",
      "44207947              $2,407.46            False  \n",
      "44206280                $137.16            False  \n",
      "...                          ...             ...  \n",
      "44208009                  $0.00              NaN  \n",
      "44208039                  $0.00              NaN  \n",
      "44208059                  $0.00              NaN  \n",
      "44206432                ($31.56)           False  \n",
      "44207038                ($75.75)           False  \n",
      "44207512                 ($7.02)           False  \n",
      "44207614                ($63.29)           False  \n",
      "44207669                ($27.25)           False  \n",
      "44207749                ($46.64)           False  \n",
      "44207923                ($91.80)           False  \n",
      "44208098                ($39.25)           False  \n",
      "44207636                ($25.80)           False  \n",
      "44207701                ($26.93)           False  \n",
      "44207960                ($18.60)           False  \n",
      "44206755               ($144.00)           False  \n",
      "44206983                ($51.38)           False  \n",
      "44208036               ($109.32)           False  \n",
      "44207225               ($148.89)           False  \n",
      "44207949                ($28.80)           False  \n",
      "44208030               ($247.20)           False  \n",
      "44207913               ($164.88)           False  \n",
      "44207922               ($316.32)           False  \n",
      "44208000               ($459.17)           False  \n",
      "44207510               ($493.20)           False  \n",
      "44207708                ($78.12)           False  \n",
      "44207924               ($948.80)           False  \n",
      "44207307               ($515.10)           False  \n",
      "44208035             ($2,760.00)           False  \n",
      "44207439             ($1,411.20)           False  \n",
      "44206947             ($1,681.06)           False  \n",
      "\n",
      "[1344 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create the boolean array: high_turnout\n",
    "high_turnout = election[' Discrepancy Value '] > 70\n",
    "\n",
    "# Filter the election DataFrame with the high_turnout array: high_turnout_df\n",
    "high_turnout_df = election[high_turnout]\n",
    "\n",
    "# Print the high_turnout_results DataFrame\n",
    "print(high_turnout_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u' AMC Item Number ', u'ITEM_DESC', u'Logic Count', u'Seafrigo Count',\n",
       "       u'Discrepancy (cases)', u' Discrepancy Value ', u'ACTIVE/INACTIVE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "election.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering columns using other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1344 entries, 44207509 to 44206947\n",
      "Data columns (total 7 columns):\n",
      " AMC Item Number       1344 non-null object\n",
      "ITEM_DESC              1344 non-null object\n",
      "Logic Count            1344 non-null int64\n",
      "Seafrigo Count         1344 non-null int64\n",
      "Discrepancy (cases)    1344 non-null int64\n",
      " Discrepancy Value     1344 non-null object\n",
      "ACTIVE/INACTIVE        1312 non-null object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 124.0+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SSari\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Create the boolean array: too_close\n",
    "too_close = election[' Discrepancy Value '] < 10\n",
    "\n",
    "# Assign np.nan to the 'winner' column where the results were too close to call\n",
    "election['ACTIVE/INACTIVE'][too_close] = np.nan\n",
    "\n",
    "# Print the output of election.info()\n",
    "print(election.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering using NaNs\n",
    "\n",
    "In certain scenarios, it may be necessary to remove rows and columns with missing data from a DataFrame. The .dropna() method is used to perform this action.\n",
    "\n",
    "also use the .shape attribute, which returns the number of rows and columns in a tuple from a DataFrame, or the number of rows from a Series, to see the effect of dropping missing values from a DataFrame.\n",
    "\n",
    "Finally, you'll use the thresh= keyword argument to drop columns from the full dataset that have more than 1000 missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1344, 2)\n",
      "(1344, 2)\n",
      "(1344, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1344 entries, 44207509 to 44206947\n",
      "Data columns (total 7 columns):\n",
      " AMC Item Number       1344 non-null object\n",
      "ITEM_DESC              1344 non-null object\n",
      "Logic Count            1344 non-null int64\n",
      "Seafrigo Count         1344 non-null int64\n",
      "Discrepancy (cases)    1344 non-null int64\n",
      " Discrepancy Value     1344 non-null object\n",
      "ACTIVE/INACTIVE        1312 non-null object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 124.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Select the 'age' and 'cabin' columns: df\n",
    "df = election[['Logic Count','Seafrigo Count']]\n",
    "\n",
    "# Print the shape of df\n",
    "print(df.shape)\n",
    "\n",
    "# Drop rows in df with how='any' and print the shape\n",
    "print(df.dropna(how='any').shape)\n",
    "\n",
    "# Drop rows in df with how='all' and print the shape\n",
    "print(df.dropna(how='all').shape)\n",
    "\n",
    "# Call .dropna() with thresh=1000 and axis='columns' and print the output of .info() from titanic\n",
    "print(election.dropna(thresh=1000, axis='columns').info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using apply() to transform a column\n",
    "\n",
    "The .apply() method can be used on a pandas DataFrame to apply an arbitrary Python function to every element"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write a function to convert degrees Fahrenheit to degrees Celsius: to_celsius\n",
    "def to_celsius(F):\n",
    "    return 5/9*(F - 32)\n",
    "\n",
    "# Apply the function over 'Mean TemperatureF' and 'Mean Dew PointF': df_celsius\n",
    "df_celsius = weather[['Mean TemperatureF', 'Mean Dew PointF']].apply(to_celsius)\n",
    "\n",
    "# Reassign the columns df_celsius\n",
    "df_celsius.columns = ['Mean TemperatureC', 'Mean Dew PointC']\n",
    "\n",
    "# Print the output of df_celsius.head()\n",
    "print(df_celsius.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using .map() with a dictionary\n",
    "\n",
    "The .map() method is used to transform values according to a Python dictionary look-up"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create the dictionary: red_vs_blue\n",
    "red_vs_blue = {'Obama':'blue','Romney':'red'}\n",
    "\n",
    "# Use the dictionary to map the 'winner' column to the new column: election['color']\n",
    "election['color'] = election['winner'].map(red_vs_blue)\n",
    "\n",
    "# Print the output of election.head()\n",
    "print(election.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using vectorized functions\n",
    "When performance is paramount, you should avoid using .apply() and .map() because those constructs perform Python for-loops over the data stored in a pandas Series or DataFrame. By using vectorized functions instead, you can loop over the data at the same speed as compiled code (C, Fortran, etc.)! NumPy, SciPy and pandas come with a variety of vectorized functions (called Universal Functions or UFuncs in NumPy).\n",
    "\n",
    "You can even write your own vectorized functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import zscore from scipy.stats\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Call zscore with election['turnout'] as input: turnout_zscore\n",
    "turnout_zscore = zscore(election['turnout'])\n",
    "\n",
    "# Print the type of turnout_zscore\n",
    "print(type(turnout_zscore))\n",
    "\n",
    "# Assign turnout_zscore to a new column: election['turnout_zscore']\n",
    "election['turnout_zscore'] = turnout_zscore\n",
    "\n",
    "# Print the output of election.head()\n",
    "print(election.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Advanced indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index objects and labeled data\n",
    "##### pandas Data Structures\n",
    "- Key building blocks\n",
    " - Indexes: Sequence of labels\n",
    " - Series: 1D array with Index\n",
    " - DataFrames: 2D array with Series as columns \n",
    "- Indexes\n",
    " - Immutable (Like dictionary keys) \n",
    " - Homogenous in data type (Like NumPy arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing index of a DataFrame"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A list comprehension is a succinct way to generate a list in one line. For example, the following list comprehension generates a list that contains the cubes of all numbers from 0 to 9: cubes = [i**3 for i in range(10)]. This is equivalent to the following code:\n",
    "\n",
    "cubes = []\n",
    "for i in range(10):\n",
    "    cubes.append(i**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>yr</th>\n",
       "      <th>name</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>maker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "      <td>ford mustang</td>\n",
       "      <td>red</td>\n",
       "      <td>27.370336</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>70</td>\n",
       "      <td>hi 1200d</td>\n",
       "      <td>green</td>\n",
       "      <td>62.199511</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asia</th>\n",
       "      <td>36.1</td>\n",
       "      <td>4</td>\n",
       "      <td>91</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>78</td>\n",
       "      <td>honda civic cvcc</td>\n",
       "      <td>blue</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>18.5</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>77</td>\n",
       "      <td>ford granada</td>\n",
       "      <td>red</td>\n",
       "      <td>34.515625</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Europe</th>\n",
       "      <td>34.3</td>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>80</td>\n",
       "      <td>audi 4000</td>\n",
       "      <td>blue</td>\n",
       "      <td>13.298178</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mpg  cyl  displ   hp  weight  accel  yr              name  color  \\\n",
       "origin                                                                       \n",
       "US       18.0    6    250   88    3139   14.5  71      ford mustang    red   \n",
       "US        9.0    8    304  193    4732   18.5  70          hi 1200d  green   \n",
       "Asia     36.1    4     91   60    1800   16.4  78  honda civic cvcc   blue   \n",
       "US       18.5    6    250   98    3525   19.0  77      ford granada    red   \n",
       "Europe   34.3    4     97   78    2188   15.8  80         audi 4000   blue   \n",
       "\n",
       "              size maker  \n",
       "origin                    \n",
       "US       27.370336     o  \n",
       "US       62.199511     o  \n",
       "Asia      9.000000     x  \n",
       "US       34.515625     o  \n",
       "Europe   13.298178     s  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "auto = pd.read_csv('auto.csv', index_col='origin ')\n",
    "\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mpg  cyl  displ   hp  weight  accel  yr              name  color  \\\n",
      "us      18.0    6    250   88    3139   14.5  71      ford mustang    red   \n",
      "us       9.0    8    304  193    4732   18.5  70          hi 1200d  green   \n",
      "asia    36.1    4     91   60    1800   16.4  78  honda civic cvcc   blue   \n",
      "us      18.5    6    250   98    3525   19.0  77      ford granada    red   \n",
      "europe  34.3    4     97   78    2188   15.8  80         audi 4000   blue   \n",
      "\n",
      "             size maker  \n",
      "us      27.370336     o  \n",
      "us      62.199511     o  \n",
      "asia     9.000000     x  \n",
      "us      34.515625     o  \n",
      "europe  13.298178     s  \n"
     ]
    }
   ],
   "source": [
    "# Create the list of new indexes: new_idx\n",
    "new_idx = [x.lower() for x in auto.index]\n",
    "\n",
    "# Assign new_idx to sales.index\n",
    "auto.index = new_idx\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(auto.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing index name labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             mpg  cyl  displ   hp  weight  accel  yr              name  color  \\\n",
      "CONTINENTS                                                                      \n",
      "us          18.0    6    250   88    3139   14.5  71      ford mustang    red   \n",
      "us           9.0    8    304  193    4732   18.5  70          hi 1200d  green   \n",
      "asia        36.1    4     91   60    1800   16.4  78  honda civic cvcc   blue   \n",
      "us          18.5    6    250   98    3525   19.0  77      ford granada    red   \n",
      "europe      34.3    4     97   78    2188   15.8  80         audi 4000   blue   \n",
      "\n",
      "                 size maker  \n",
      "CONTINENTS                   \n",
      "us          27.370336     o  \n",
      "us          62.199511     o  \n",
      "asia         9.000000     x  \n",
      "us          34.515625     o  \n",
      "europe      13.298178     s  \n",
      "FEATURES     mpg  cyl  displ   hp  weight  accel  yr              name  color  \\\n",
      "CONTINENTS                                                                      \n",
      "us          18.0    6    250   88    3139   14.5  71      ford mustang    red   \n",
      "us           9.0    8    304  193    4732   18.5  70          hi 1200d  green   \n",
      "asia        36.1    4     91   60    1800   16.4  78  honda civic cvcc   blue   \n",
      "us          18.5    6    250   98    3525   19.0  77      ford granada    red   \n",
      "europe      34.3    4     97   78    2188   15.8  80         audi 4000   blue   \n",
      "\n",
      "FEATURES         size maker  \n",
      "CONTINENTS                   \n",
      "us          27.370336     o  \n",
      "us          62.199511     o  \n",
      "asia         9.000000     x  \n",
      "us          34.515625     o  \n",
      "europe      13.298178     s  \n"
     ]
    }
   ],
   "source": [
    "# Assign the string 'MONTHS' to sales.index.name\n",
    "auto.index.name = 'CONTINENTS'\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(auto.head())\n",
    "\n",
    "# Assign the string 'PRODUCTS' to sales.columns.name \n",
    "auto.columns.name = 'FEATURES'\n",
    "\n",
    "# Print the sales dataframe again\n",
    "print(auto.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an index, then a DataFrame\n",
    "\n",
    "You can also build the DataFrame and index independently, and then put them together. If you take this route, be careful, as any mistakes in generating the DataFrame or the index can cause the data and the index to be aligned incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES   mpg  cyl  displ   hp  weight  accel  yr              name  color  \\\n",
      "Jan       18.0    6    250   88    3139   14.5  71      ford mustang    red   \n",
      "Feb        9.0    8    304  193    4732   18.5  70          hi 1200d  green   \n",
      "Mar       36.1    4     91   60    1800   16.4  78  honda civic cvcc   blue   \n",
      "Apr       18.5    6    250   98    3525   19.0  77      ford granada    red   \n",
      "May       34.3    4     97   78    2188   15.8  80         audi 4000   blue   \n",
      "\n",
      "FEATURES       size maker  \n",
      "Jan       27.370336     o  \n",
      "Feb       62.199511     o  \n",
      "Mar        9.000000     x  \n",
      "Apr       34.515625     o  \n",
      "May       13.298178     s  \n"
     ]
    }
   ],
   "source": [
    "# Generate the list of months: months\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun','Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun','Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun','Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun','Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']\n",
    "\n",
    "# Assign months to sales.index\n",
    "auto.index = months\n",
    "\n",
    "# Print the modified sales DataFrame\n",
    "print(auto.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical indexing\n",
    "\n",
    "### Extracting data with a MultiIndex\n",
    "\n",
    "Extracting elements from the outermost level of a MultiIndex is just like in the case of a single-level Index. You can use the .loc[] accessor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print sales.loc[['CA', 'TX']]\n",
    "print(auto.loc[['CA', 'TX']])\n",
    "\n",
    "# Print sales['CA':'TX']\n",
    "print(auto['CA':'TX'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "                 eggs  salt  spam\n",
    "    state month                  \n",
    "    CA    1        47  12.0    17\n",
    "          2       110  50.0    31\n",
    "    TX    1       132   NaN    52\n",
    "          2       205  60.0    55\n",
    "\n",
    "After it Runs:\n",
    "        \n",
    "                 eggs  salt  spam\n",
    "    state month                  \n",
    "    CA    1        47  12.0    17\n",
    "          2       110  50.0    31\n",
    "    NY    1       221  89.0    72\n",
    "          2        77  87.0    20\n",
    "    TX    1       132   NaN    52\n",
    "          2       205  60.0    55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting & sorting a MultiIndex\n",
    "\n",
    "With a MultiIndex, you should always ensure the index is sorted. You can skip this only if you know the data is already sorted on the index fields."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Set the index to be the columns ['state', 'month']: sales\n",
    "sales = sales.set_index(['state', 'month'])\n",
    "\n",
    "# Sort the MultiIndex: sales\n",
    "sales = sales.sort_index()\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "                 eggs  salt  spam\n",
    "    state month                  \n",
    "    CA    1        47  12.0    17\n",
    "          2       110  50.0    31\n",
    "    NY    1       221  89.0    72\n",
    "          2        77  87.0    20\n",
    "    TX    1       132   NaN    52\n",
    "          2       205  60.0    55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using .loc[] with nonunique indexes\n",
    "\n",
    "it is always preferable to have a meaningful index that uniquely identifies each row. Even though pandas does not require unique index values in DataFrames, it works better if the index values are indeed unique. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Set the index to the column 'state': sales\n",
    "sales = sales.set_index('state')\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(sales)\n",
    "\n",
    "# Access the data from 'NY'\n",
    "print(sales.loc['NY'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "           month  eggs  salt  spam\n",
    "    state                         \n",
    "    CA         1    47  12.0    17\n",
    "    CA         2   110  50.0    31\n",
    "    NY         1   221  89.0    72\n",
    "    NY         2    77  87.0    20\n",
    "    TX         1   132   NaN    52\n",
    "    TX         2   205  60.0    55\n",
    "           month  eggs  salt  spam\n",
    "    state                         \n",
    "    NY         1   221  89.0    72\n",
    "    NY         2    77  87.0    20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing multiple levels of a MultiIndex\n",
    "\n",
    "Looking up indexed data is fast and efficient. And you have already seen that lookups based on the outermost level of a MultiIndex work just like lookups on DataFrames that have a single-level Index.\n",
    "\n",
    "Looking up data based on inner levels of a MultiIndex can be a bit trickier. In this exercise, you will use your sales DataFrame to do some increasingly complex lookups.\n",
    "\n",
    "The trickiest of all these lookups are when you want to access some inner levels of the index. In this case, you need to use slice(None) in the slicing parameter for the outermost dimension(s) instead of the usual :, or use pd.IndexSlice. \n",
    "\n",
    "stocks.loc[(slice(None), slice('2016-10-03', '2016-10-04')), :]\n",
    "\n",
    "Pay particular attention to the tuple (slice(None), slice('2016-10-03', '2016-10-04'))."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Look up data for NY in month 1: NY_month1\n",
    "NY_month1 = sales.loc[('NY', 1), :]\n",
    "\n",
    "# Look up data for CA and TX in month 2: CA_TX_month2\n",
    "CA_TX_month2 = sales.loc[(['CA', 'TX'], 2), :]\n",
    "\n",
    "# Look up data for all states in month 2: all_month2\n",
    "all_month2 = sales.loc[(slice(None), 2), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting a single variable"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Suppose you started a blog for a band, and you would like to log how many visitors you have had, and how many signed-up for your newsletter. To help design the tours later, you track where the visitors are. A DataFrame called users consisting of this information has been pre-loaded for you.\n",
    "\n",
    "Inspect users in the IPython Shell and make a note of which variable you want to use to index the rows ('weekday'), which variable you want to use to index the columns ('city'), and which variable will populate the values in the cells ('visitors'). Try to visualize what the result should be.\n",
    "\n",
    "For example, in the video, Dhavide used 'treatment' to index the rows, 'gender' to index the columns, and 'response' to populate the cells. Prior to pivoting, the DataFrame looked like this:\n",
    "\n",
    "   id treatment gender  response\n",
    "0   1         A      F         5\n",
    "1   2         A      M         3\n",
    "2   3         B      F         8\n",
    "3   4         B      M         9\n",
    "\n",
    "After pivoting:\n",
    "\n",
    "gender     F  M\n",
    "treatment      \n",
    "A          5  3\n",
    "B          8  9"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Pivot the users DataFrame: visitors_pivot\n",
    "visitors_pivot = users.pivot(index='weekday',columns='city',values='visitors')\n",
    "\n",
    "# Print the pivoted DataFrame\n",
    "print(visitors_pivot)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    city     Austin  Dallas\n",
    "    weekday                \n",
    "    Mon         326     456\n",
    "    Sun         139     237"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting all variables\n",
    "\n",
    "If you do not select any particular variables, all of them will be pivoted. In this case - with the users DataFrame - both 'visitors' and 'signups' will be pivoted, creating hierarchical column labels."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Pivot users with signups indexed by weekday and city: signups_pivot\n",
    "signups_pivot = users.pivot(index='weekday',columns='city',values='signups')\n",
    "\n",
    "# Print signups_pivot\n",
    "print(signups_pivot)\n",
    "\n",
    "# Pivot users pivoted by both signups and visitors: pivot\n",
    "pivot = users.pivot(index='weekday',columns='city')\n",
    "\n",
    "# Print the pivoted DataFrame\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    city     Austin  Dallas\n",
    "    weekday                \n",
    "    Mon           3       5\n",
    "    Sun           7      12\n",
    "            visitors        signups       \n",
    "    city      Austin Dallas  Austin Dallas\n",
    "    weekday                               \n",
    "    Mon          326    456       3      5\n",
    "    Sun          139    237       7     12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking & unstacking DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES     \n",
      "mpg       Jan      18\n",
      "          Feb       9\n",
      "          Mar    36.1\n",
      "          Apr    18.5\n",
      "          May    34.3\n",
      "dtype: object\n",
      "     FEATURES\n",
      "Jan  mpg           18\n",
      "     cyl            6\n",
      "     displ        250\n",
      "     hp            88\n",
      "     weight      3139\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Unstack users by 'weekday': byweekday\n",
    "byweekday = auto.unstack('maker')\n",
    "\n",
    "# Print the byweekday DataFrame\n",
    "print(byweekday.head())\n",
    "\n",
    "# Stack byweekday by 'weekday' and print it\n",
    "print(auto.stack(level='FEATURES').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring the index order\n",
    "\n",
    "You will now use .swaplevel(0, 1) to flip the index levels. Note they won't be sorted. To sort them, you will have to follow up with a .sort_index(). You will then obtain the original DataFrame. Note that an unsorted index leads to slicing failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES     \n",
      "mpg       Jan                       18\n",
      "cyl       Jan                        6\n",
      "displ     Jan                      250\n",
      "hp        Jan                       88\n",
      "weight    Jan                     3139\n",
      "accel     Jan                     14.5\n",
      "yr        Jan                       71\n",
      "name      Jan             ford mustang\n",
      "color     Jan                      red\n",
      "size      Jan                  27.3703\n",
      "maker     Jan                        o\n",
      "mpg       Feb                        9\n",
      "cyl       Feb                        8\n",
      "displ     Feb                      304\n",
      "hp        Feb                      193\n",
      "weight    Feb                     4732\n",
      "accel     Feb                     18.5\n",
      "yr        Feb                       70\n",
      "name      Feb                 hi 1200d\n",
      "color     Feb                    green\n",
      "size      Feb                  62.1995\n",
      "maker     Feb                        o\n",
      "mpg       Mar                     36.1\n",
      "cyl       Mar                        4\n",
      "displ     Mar                       91\n",
      "hp        Mar                       60\n",
      "weight    Mar                     1800\n",
      "accel     Mar                     16.4\n",
      "yr        Mar                       78\n",
      "name      Mar         honda civic cvcc\n",
      "                         ...          \n",
      "hp        Apr                       95\n",
      "weight    Apr                     2372\n",
      "accel     Apr                       15\n",
      "yr        Apr                       70\n",
      "name      Apr    toyota corona mark ii\n",
      "color     Apr                     blue\n",
      "size      Apr                  15.6288\n",
      "maker     Apr                        x\n",
      "mpg       May                       21\n",
      "cyl       May                        6\n",
      "displ     May                      231\n",
      "hp        May                      110\n",
      "weight    May                     3039\n",
      "accel     May                       15\n",
      "yr        May                       75\n",
      "name      May            buick skyhawk\n",
      "color     May                      red\n",
      "size      May                  25.6542\n",
      "maker     May                        o\n",
      "mpg       Jun                     31.3\n",
      "cyl       Jun                        4\n",
      "displ     Jun                      120\n",
      "hp        Jun                       75\n",
      "weight    Jun                     2542\n",
      "accel     Jun                     17.5\n",
      "yr        Jun                       80\n",
      "name      Jun                mazda 626\n",
      "color     Jun                     blue\n",
      "size      Jun                  17.9493\n",
      "maker     Jun                        x\n",
      "Length: 330, dtype: object\n",
      "FEATURES     \n",
      "accel     Apr      19\n",
      "          Apr    10.5\n",
      "          Apr      14\n",
      "          Apr      21\n",
      "          Apr      15\n",
      "dtype: object\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Stack 'city' back into the index of bycity: newusers\n",
    "newusers = auto.stack(level='FEATURES')\n",
    "\n",
    "# Swap the levels of the index of newusers: newusers\n",
    "newusers = newusers.swaplevel(0,1)\n",
    "\n",
    "# Print newusers and verify that the index is not sorted\n",
    "print(newusers)\n",
    "\n",
    "# Sort the index of newusers: newusers\n",
    "newusers = newusers.sort_index()\n",
    "\n",
    "# Print newusers and verify that the index is now sorted\n",
    "print(newusers.head())\n",
    "\n",
    "# Verify that the new DataFrame is equal to the original\n",
    "print(newusers.equals(auto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melting DataFrames\n",
    "\n",
    "### Adding names for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES index   mpg  cyl  displ   hp  weight  accel  yr              name  \\\n",
      "0          Jan  18.0    6    250   88    3139   14.5  71      ford mustang   \n",
      "1          Feb   9.0    8    304  193    4732   18.5  70          hi 1200d   \n",
      "2          Mar  36.1    4     91   60    1800   16.4  78  honda civic cvcc   \n",
      "3          Apr  18.5    6    250   98    3525   19.0  77      ford granada   \n",
      "4          May  34.3    4     97   78    2188   15.8  80         audi 4000   \n",
      "\n",
      "FEATURES  color       size maker  \n",
      "0           red  27.370336     o  \n",
      "1         green  62.199511     o  \n",
      "2          blue   9.000000     x  \n",
      "3           red  34.515625     o  \n",
      "4          blue  13.298178     s  \n",
      "    mpg FEATURES   yr\n",
      "0  18.0    index  Jan\n",
      "1   9.0    index  Feb\n",
      "2  36.1    index  Mar\n",
      "3  18.5    index  Apr\n",
      "4  34.3    index  May\n"
     ]
    }
   ],
   "source": [
    "# Reset the index: visitors_by_city_weekday\n",
    "visitors_by_city_weekday = auto.reset_index() \n",
    "\n",
    "# Print visitors_by_city_weekday\n",
    "print(visitors_by_city_weekday.head())\n",
    "\n",
    "# Melt visitors_by_city_weekday: visitors\n",
    "visitors = pd.melt(visitors_by_city_weekday, id_vars=['mpg'], value_name='yr')\n",
    "\n",
    "# Print visitors\n",
    "print(visitors.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going from wide to long\n",
    "\n",
    "You can move multiple columns into a single column (making the data long and skinny) by \"melting\" multiple columns. In this exercise, you will practice doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                name maker FEATURES  value\n",
      "0                       ford mustang     o       yr     71\n",
      "1                           hi 1200d     o       yr     70\n",
      "2                   honda civic cvcc     x       yr     78\n",
      "3                       ford granada     o       yr     77\n",
      "4                          audi 4000     s       yr     80\n",
      "5                       datsun 200sx     x       yr     81\n",
      "6                     toyota corolla     x       yr     80\n",
      "7                volkswagen 411 (sw)     s       yr     72\n",
      "8            mercury cougar brougham     o       yr     77\n",
      "9                        ford torino     o       yr     70\n",
      "10                         vw pickup     s       yr     82\n",
      "11             pontiac sunbird coupe     o       yr     77\n",
      "12                     dodge rampage     o       yr     82\n",
      "13                          ford ltd     o       yr     75\n",
      "14             chevrolet monte carlo     o       yr     70\n",
      "15  chevrolet chevelle concours (sw)     o       yr     72\n",
      "16                     renault 5 gtl     s       yr     77\n",
      "17                        chevy s-10     o       yr     82\n",
      "18               toyota corolla 1200     x       yr     74\n",
      "19                        mazda rx-4     x       yr     77\n",
      "20           plymouth valiant custom     o       yr     75\n",
      "21                     buick century     o       yr     75\n",
      "22                  ford gran torino     o       yr     74\n",
      "23               dodge challenger se     o       yr     70\n",
      "24                     pontiac astro     o       yr     75\n",
      "25              fiat 124 sport coupe     s       yr     73\n",
      "26                  toyota celica gt     x       yr     82\n",
      "27             toyota corona mark ii     x       yr     70\n",
      "28                     buick skyhawk     o       yr     75\n",
      "29                         mazda 626     x       yr     80\n",
      "30                      ford mustang     o       hp     88\n",
      "31                          hi 1200d     o       hp    193\n",
      "32                  honda civic cvcc     x       hp     60\n",
      "33                      ford granada     o       hp     98\n",
      "34                         audi 4000     s       hp     78\n",
      "35                      datsun 200sx     x       hp    100\n",
      "36                    toyota corolla     x       hp     75\n",
      "37               volkswagen 411 (sw)     s       hp     76\n",
      "38           mercury cougar brougham     o       hp    130\n",
      "39                       ford torino     o       hp    140\n",
      "40                         vw pickup     s       hp     52\n",
      "41             pontiac sunbird coupe     o       hp     88\n",
      "42                     dodge rampage     o       hp     84\n",
      "43                          ford ltd     o       hp    148\n",
      "44             chevrolet monte carlo     o       hp    150\n",
      "45  chevrolet chevelle concours (sw)     o       hp    130\n",
      "46                     renault 5 gtl     s       hp     58\n",
      "47                        chevy s-10     o       hp     82\n",
      "48               toyota corolla 1200     x       hp     65\n",
      "49                        mazda rx-4     x       hp    110\n",
      "50           plymouth valiant custom     o       hp     95\n",
      "51                     buick century     o       hp    110\n",
      "52                  ford gran torino     o       hp    140\n",
      "53               dodge challenger se     o       hp    170\n",
      "54                     pontiac astro     o       hp     78\n",
      "55              fiat 124 sport coupe     s       hp     90\n",
      "56                  toyota celica gt     x       hp     96\n",
      "57             toyota corona mark ii     x       hp     95\n",
      "58                     buick skyhawk     o       hp    110\n",
      "59                         mazda 626     x       hp     75\n"
     ]
    }
   ],
   "source": [
    "# Melt users: skinny\n",
    "skinny = pd.melt(auto, id_vars=['name', 'maker'], value_vars=['yr','hp'])\n",
    "\n",
    "# Print skinny\n",
    "print(skinny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining key-value pairs with melt()\n",
    "\n",
    "Sometimes, all you need is some key-value pairs, and the context does not matter. If said context is in the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES   mpg  cyl  displ   hp  weight  accel              name  color  \\\n",
      "maker yr                                                                  \n",
      "o     71  18.0    6    250   88    3139   14.5      ford mustang    red   \n",
      "      70   9.0    8    304  193    4732   18.5          hi 1200d  green   \n",
      "x     78  36.1    4     91   60    1800   16.4  honda civic cvcc   blue   \n",
      "o     77  18.5    6    250   98    3525   19.0      ford granada    red   \n",
      "s     80  34.3    4     97   78    2188   15.8         audi 4000   blue   \n",
      "\n",
      "FEATURES       size  \n",
      "maker yr             \n",
      "o     71  27.370336  \n",
      "      70  62.199511  \n",
      "x     78   9.000000  \n",
      "o     77  34.515625  \n",
      "s     80  13.298178  \n",
      "  FEATURES value\n",
      "0      mpg    18\n",
      "1      mpg     9\n",
      "2      mpg  36.1\n",
      "3      mpg  18.5\n",
      "4      mpg  34.3\n"
     ]
    }
   ],
   "source": [
    "# Set the new index: users_idx\n",
    "users_idx = auto.set_index(['maker','yr'])\n",
    "\n",
    "# Print the users_idx DataFrame\n",
    "print(users_idx.head())\n",
    "\n",
    "# Obtain the key-value pairs: kv_pairs\n",
    "kv_pairs = pd.melt(users_idx,col_level=0)\n",
    "\n",
    "# Print the key-value pairs\n",
    "print(kv_pairs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES                         accel                                        \\\n",
      "yr                                  70  71    72  73  74    75  77  78    80   \n",
      "name                                                                           \n",
      "audi 4000                          NaN NaN   NaN NaN NaN   NaN NaN NaN  15.8   \n",
      "buick century                      NaN NaN   NaN NaN NaN  21.0 NaN NaN   NaN   \n",
      "buick skyhawk                      NaN NaN   NaN NaN NaN  15.0 NaN NaN   NaN   \n",
      "chevrolet chevelle concours (sw)   NaN NaN  14.0 NaN NaN   NaN NaN NaN   NaN   \n",
      "chevrolet monte carlo              9.5 NaN   NaN NaN NaN   NaN NaN NaN   NaN   \n",
      "\n",
      "FEATURES                             ... weight                              \\\n",
      "yr                                81 ...     71      72  73  74      75  77   \n",
      "name                                 ...                                      \n",
      "audi 4000                        NaN ...    NaN     NaN NaN NaN     NaN NaN   \n",
      "buick century                    NaN ...    NaN     NaN NaN NaN  3907.0 NaN   \n",
      "buick skyhawk                    NaN ...    NaN     NaN NaN NaN  3039.0 NaN   \n",
      "chevrolet chevelle concours (sw) NaN ...    NaN  4098.0 NaN NaN     NaN NaN   \n",
      "chevrolet monte carlo            NaN ...    NaN     NaN NaN NaN     NaN NaN   \n",
      "\n",
      "FEATURES                                              \n",
      "yr                                78      80  81  82  \n",
      "name                                                  \n",
      "audi 4000                        NaN  2188.0 NaN NaN  \n",
      "buick century                    NaN     NaN NaN NaN  \n",
      "buick skyhawk                    NaN     NaN NaN NaN  \n",
      "chevrolet chevelle concours (sw) NaN     NaN NaN NaN  \n",
      "chevrolet monte carlo            NaN     NaN NaN NaN  \n",
      "\n",
      "[5 rows x 77 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create the DataFrame with the appropriate pivot table: by_city_day\n",
    "by_city_day = auto.pivot_table(index='name',columns='yr')\n",
    "\n",
    "# Print by_city_day\n",
    "print(by_city_day.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using other aggregations in pivot tables\n",
    "\n",
    "You can also use aggregation functions with in a pivot table by specifying the aggfunc parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES                          accel  color  cyl  displ  hp  maker  mpg  \\\n",
      "name                                                                         \n",
      "audi 4000                             1      1    1      1   1      1    1   \n",
      "buick century                         1      1    1      1   1      1    1   \n",
      "buick skyhawk                         1      1    1      1   1      1    1   \n",
      "chevrolet chevelle concours (sw)      1      1    1      1   1      1    1   \n",
      "chevrolet monte carlo                 1      1    1      1   1      1    1   \n",
      "\n",
      "FEATURES                          size  weight  yr  \n",
      "name                                                \n",
      "audi 4000                            1       1   1  \n",
      "buick century                        1       1   1  \n",
      "buick skyhawk                        1       1   1  \n",
      "chevrolet chevelle concours (sw)     1       1   1  \n",
      "chevrolet monte carlo                1       1   1  \n",
      "==========================================\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Use a pivot table to display the count of each column: count_by_weekday1\n",
    "count_by_weekday1 = auto.pivot_table(index='name',aggfunc='count')\n",
    "\n",
    "# Print count_by_weekday\n",
    "print(count_by_weekday1.head())\n",
    "\n",
    "# Replace 'aggfunc='count'' with 'aggfunc=len': count_by_weekday2\n",
    "count_by_weekday2 = auto.pivot_table(index='yr',aggfunc=len)\n",
    "\n",
    "\n",
    "# Verify that the same result is obtained\n",
    "print('==========================================')\n",
    "print(count_by_weekday1.equals(count_by_weekday2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using margins in pivot tables\n",
    "\n",
    "Sometimes it's useful to add totals in the margins of a pivot table. You can do this with the argument margins=True. In this exercise, you will practice using margins in a pivot table along with a new aggregation function: sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURES                          accel  cyl  displ   hp   mpg       size  \\\n",
      "name                                                                        \n",
      "audi 4000                          15.8    4     97   78  34.3  13.298178   \n",
      "buick century                      21.0    6    231  110  17.0  42.401803   \n",
      "buick skyhawk                      15.0    6    231  110  21.0  25.654225   \n",
      "chevrolet chevelle concours (sw)   14.0    8    307  130  13.0  46.648900   \n",
      "chevrolet monte carlo               9.5    8    400  150  15.0  39.292003   \n",
      "\n",
      "FEATURES                          weight  yr  \n",
      "name                                          \n",
      "audi 4000                           2188  80  \n",
      "buick century                       3907  75  \n",
      "buick skyhawk                       3039  75  \n",
      "chevrolet chevelle concours (sw)    4098  72  \n",
      "chevrolet monte carlo               3761  70  \n",
      "FEATURES  accel   cyl   displ     hp   mpg        size   weight\n",
      "yr                                                             \n",
      "70         63.5  36.0  1502.0  748.0  80.0  185.427497  17877.0\n",
      "71         14.5   6.0   250.0   88.0  18.0   27.370336   3139.0\n",
      "72         32.0  12.0   428.0  206.0  35.0   64.163125   6609.0\n",
      "73         15.5   4.0    98.0   90.0  26.0   14.250625   2265.0\n",
      "74         35.0  12.0   373.0  205.0  48.0   56.996603   5977.0\n"
     ]
    }
   ],
   "source": [
    "# Create the DataFrame with the appropriate pivot table: signups_and_visitors\n",
    "signups_and_visitors = auto.pivot_table(index='name',aggfunc=sum)\n",
    "\n",
    "# Print signups_and_visitors\n",
    "print(signups_and_visitors.head())\n",
    "\n",
    "# Add in the margins: signups_and_visitors_total \n",
    "signups_and_visitors_total = auto.pivot_table(index='yr',margins=True,aggfunc=sum)\n",
    "\n",
    "# Print signups_and_visitors_total\n",
    "print(signups_and_visitors_total.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantages of categorical data types\n",
    "\n",
    "- Computations are faster.\n",
    "- Categorical data require less space in memory.\n",
    "\n",
    "### Grouping by multiple columns\n",
    "\n",
    ".groupby() to analyze the distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "audi 4000                           1\n",
      "buick century                       1\n",
      "buick skyhawk                       1\n",
      "chevrolet chevelle concours (sw)    1\n",
      "chevrolet monte carlo               1\n",
      "Name: yr, dtype: int64\n",
      "name                              maker\n",
      "audi 4000                         s        1\n",
      "buick century                     o        1\n",
      "buick skyhawk                     o        1\n",
      "chevrolet chevelle concours (sw)  o        1\n",
      "chevrolet monte carlo             o        1\n",
      "Name: hp, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group titanic by 'pclass'\n",
    "by_class = auto.groupby('name')\n",
    "\n",
    "# Aggregate 'survived' column of by_class by count\n",
    "count_by_class = by_class['yr'].count()\n",
    "\n",
    "# Print count_by_class\n",
    "print(count_by_class.head())\n",
    "\n",
    "# Group titanic by 'embarked' and 'pclass'\n",
    "by_mult = auto.groupby(['name','maker'])\n",
    "\n",
    "# Aggregate 'survived' column of by_mult by count\n",
    "count_mult = by_mult['hp'].count()\n",
    "\n",
    "# Print count_mult\n",
    "print(count_mult.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by another series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "audi 4000                            78\n",
      "buick century                       110\n",
      "buick skyhawk                       110\n",
      "chevrolet chevelle concours (sw)    130\n",
      "chevrolet monte carlo               150\n",
      "chevy s-10                           82\n",
      "datsun 200sx                        100\n",
      "dodge challenger se                 170\n",
      "dodge rampage                        84\n",
      "fiat 124 sport coupe                 90\n",
      "ford gran torino                    140\n",
      "ford granada                         98\n",
      "ford ltd                            148\n",
      "ford mustang                         88\n",
      "ford torino                         140\n",
      "hi 1200d                            193\n",
      "honda civic cvcc                     60\n",
      "mazda 626                            75\n",
      "mazda rx-4                          110\n",
      "mercury cougar brougham             130\n",
      "plymouth valiant custom              95\n",
      "pontiac astro                        78\n",
      "pontiac sunbird coupe                88\n",
      "renault 5 gtl                        58\n",
      "toyota celica gt                     96\n",
      "toyota corolla                       75\n",
      "toyota corolla 1200                  65\n",
      "toyota corona mark ii                95\n",
      "volkswagen 411 (sw)                  76\n",
      "vw pickup                            52\n",
      "Name: hp, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read life_fname into a DataFrame: life\n",
    "#life = pd.read_csv(life_fname, index_col='Country')\n",
    "\n",
    "# Read regions_fname into a DataFrame: regions\n",
    "#regions = pd.read_csv(regions_fname, index_col='Country')\n",
    "\n",
    "# Group life by regions['region']: life_by_region\n",
    "life_by_region = auto.groupby(auto['name'])\n",
    "\n",
    "# Print the mean over the '2010' column of life_by_region\n",
    "print(life_by_region['hp'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby and aggregation\n",
    "\n",
    "#### Aggregation functions\n",
    "- string names \n",
    "- sum\n",
    "- mean\n",
    "- count\n",
    "\n",
    "### Computing multiple aggregates of multiple columns\n",
    "\n",
    "The .agg() method can be used with a tuple or list of aggregations as input. When applying multiple aggregations on multiple columns, the aggregated DataFrame has a multi-level column index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "audi 4000                           80\n",
      "buick century                       75\n",
      "buick skyhawk                       75\n",
      "chevrolet chevelle concours (sw)    72\n",
      "chevrolet monte carlo               70\n",
      "chevy s-10                          82\n",
      "datsun 200sx                        81\n",
      "dodge challenger se                 70\n",
      "dodge rampage                       82\n",
      "fiat 124 sport coupe                73\n",
      "ford gran torino                    74\n",
      "ford granada                        77\n",
      "ford ltd                            75\n",
      "ford mustang                        71\n",
      "ford torino                         70\n",
      "hi 1200d                            70\n",
      "honda civic cvcc                    78\n",
      "mazda 626                           80\n",
      "mazda rx-4                          77\n",
      "mercury cougar brougham             77\n",
      "plymouth valiant custom             75\n",
      "pontiac astro                       75\n",
      "pontiac sunbird coupe               77\n",
      "renault 5 gtl                       77\n",
      "toyota celica gt                    82\n",
      "toyota corolla                      80\n",
      "toyota corolla 1200                 74\n",
      "toyota corona mark ii               70\n",
      "volkswagen 411 (sw)                 72\n",
      "vw pickup                           82\n",
      "Name: (yr, max), dtype: int64\n",
      "name\n",
      "audi 4000                            78\n",
      "buick century                       110\n",
      "buick skyhawk                       110\n",
      "chevrolet chevelle concours (sw)    130\n",
      "chevrolet monte carlo               150\n",
      "chevy s-10                           82\n",
      "datsun 200sx                        100\n",
      "dodge challenger se                 170\n",
      "dodge rampage                        84\n",
      "fiat 124 sport coupe                 90\n",
      "ford gran torino                    140\n",
      "ford granada                         98\n",
      "ford ltd                            148\n",
      "ford mustang                         88\n",
      "ford torino                         140\n",
      "hi 1200d                            193\n",
      "honda civic cvcc                     60\n",
      "mazda 626                            75\n",
      "mazda rx-4                          110\n",
      "mercury cougar brougham             130\n",
      "plymouth valiant custom              95\n",
      "pontiac astro                        78\n",
      "pontiac sunbird coupe                88\n",
      "renault 5 gtl                        58\n",
      "toyota celica gt                     96\n",
      "toyota corolla                       75\n",
      "toyota corolla 1200                  65\n",
      "toyota corona mark ii                95\n",
      "volkswagen 411 (sw)                  76\n",
      "vw pickup                            52\n",
      "Name: (hp, median), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group titanic by 'pclass': by_class\n",
    "by_class = auto.groupby('name')\n",
    "\n",
    "# Select 'age' and 'fare'\n",
    "by_class_sub = by_class[['yr','hp']]\n",
    "\n",
    "# Aggregate by_class_sub by 'max' and 'median': aggregated\n",
    "aggregated = by_class_sub.agg(['max', 'median'])\n",
    "\n",
    "# Print the maximum age in each class\n",
    "print(aggregated.loc[:, ('yr','max')])\n",
    "\n",
    "# Print the median fare in each class\n",
    "print(aggregated.loc[:, ('hp','median')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating on index levels/fields\n",
    "\n",
    "If you have a DataFrame with a multi-level row index, the individual levels can be used to perform the groupby. This allows advanced aggregation techniques to be applied along one or more levels in the index and across one or more columns."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Read the CSV file into a DataFrame and sort the index: gapminder\n",
    "gapminder = pd.read_csv('gapminder.csv', index_col=['Year','region','Country']).sort_index()\n",
    "\n",
    "# Group gapminder by 'Year' and 'region': by_year_region\n",
    "by_year_region = gapminder.groupby(level=['Year','region'])\n",
    "\n",
    "# Define the function to compute spread: spread\n",
    "def spread(series):\n",
    "    return series.max() - series.min()\n",
    "\n",
    "# Create the dictionary: aggregator\n",
    "aggregator = {'population':'sum', 'child_mortality':'mean', 'gdp':spread}\n",
    "\n",
    "# Aggregate by_year_region using the dictionary: aggregated\n",
    "aggregated = by_year_region.agg(aggregator)\n",
    "\n",
    "# Print the last 6 entries of aggregated \n",
    "print(aggregated.tail(6))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "                                     child_mortality       gdp    population\n",
    "    Year region                                                             \n",
    "    2013 America                           17.745833   49634.0  9.629087e+08\n",
    "         East Asia & Pacific               22.285714  134744.0  2.244209e+09\n",
    "         Europe & Central Asia              9.831875   86418.0  8.968788e+08\n",
    "         Middle East & North Africa        20.221500  128676.0  4.030504e+08\n",
    "         South Asia                        46.287500   11469.0  1.701241e+09\n",
    "         Sub-Saharan Africa                76.944490   32035.0  9.205996e+08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping on a function of the index\n",
    "\n",
    "Groubpy operations can also be performed on transformations of the index values. In the case of a DateTimeIndex, we can extract portions of the datetime over which to group."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Read file: sales\n",
    "sales = pd.read_csv('sales.csv', index_col='Date',parse_dates=True)\n",
    "\n",
    "# Create a groupby object: by_day\n",
    "by_day = sales.groupby(sales.index.strftime('%a'))\n",
    "\n",
    "# Create sum: units_sum\n",
    "units_sum = by_day['Units'].sum()\n",
    "\n",
    "# Print units_sum\n",
    "print(units_sum)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    Mon    48\n",
    "    Sat     7\n",
    "    Thu    59\n",
    "    Tue    13\n",
    "    Wed    48\n",
    "    Name: Units, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby and transformation\n",
    "\n",
    "### Detecting outliers with Z-Scores\n",
    "\n",
    "using the zscore function, you can apply a .transform() method after grouping to apply a function to groups of data independently. The z-score is also useful to find outliers: a z-score value of +/- 3 is generally considered to be an outlier."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import zscore\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Group gapminder_2010: standardized\n",
    "standardized = gapminder_2010.groupby('region')['life','fertility'].transform(zscore)\n",
    "\n",
    "# Construct a Boolean Series to identify outliers: outliers\n",
    "outliers = (standardized['life'] < -3) | (standardized['fertility'] > 3)\n",
    "\n",
    "# Filter gapminder_2010 by the outliers: gm_outliers\n",
    "gm_outliers = gapminder_2010.loc[outliers]\n",
    "\n",
    "# Print gm_outliers\n",
    "print(gm_outliers)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "                 fertility    life  population  child_mortality     gdp  \\\n",
    "    Country                                                               \n",
    "    Guatemala        3.974  71.100  14388929.0             34.5  6849.0   \n",
    "    Haiti            3.350  45.000   9993247.0            208.8  1518.0   \n",
    "    Tajikistan       3.780  66.830   6878637.0             52.6  2110.0   \n",
    "    Timor-Leste      6.237  65.952   1124355.0             63.8  1777.0   \n",
    "    \n",
    "                                region  \n",
    "    Country                             \n",
    "    Guatemala                  America  \n",
    "    Haiti                      America  \n",
    "    Tajikistan   Europe & Central Asia  \n",
    "    Timor-Leste    East Asia & Pacific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing data (imputation) by group\n",
    "\n",
    "Many statistical and machine learning packages cannot determine the best action to take when missing data entries are encountered. Dealing with missing data is natural in pandas (both in using the default behavior and in defining a custom behavior). In Chapter 1, you practiced using the .dropna() method to drop missing values. Now, you will practice imputing missing values. You can use .groupby() and .transform() to fill missing data appropriately for each group."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a groupby object: by_sex_class\n",
    "by_sex_class = titanic.groupby(['sex','pclass'])\n",
    "\n",
    "# Write a function that imputes median\n",
    "def impute_median(series):\n",
    "    return series.fillna(series.median())\n",
    "\n",
    "# Impute age and assign to titanic['age']\n",
    "titanic.age = by_sex_class['age'].apply(impute_median)\n",
    "\n",
    "# Print the output of titanic.tail(10)\n",
    "print(titanic.tail(10))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "          pclass  survived                                     name     sex   age  \\\n",
    "    1299       3         0                      Yasbeck, Mr. Antoni    male  27.0   \n",
    "    1300       3         1  Yasbeck, Mrs. Antoni (Selini Alexander)  female  15.0   \n",
    "    1301       3         0                     Youseff, Mr. Gerious    male  45.5   \n",
    "    1302       3         0                        Yousif, Mr. Wazli    male  25.0   \n",
    "    1303       3         0                    Yousseff, Mr. Gerious    male  25.0   \n",
    "    1304       3         0                     Zabour, Miss. Hileni  female  14.5   \n",
    "    1305       3         0                    Zabour, Miss. Thamine  female  22.0   \n",
    "    1306       3         0                Zakarian, Mr. Mapriededer    male  26.5   \n",
    "    1307       3         0                      Zakarian, Mr. Ortin    male  27.0   \n",
    "    1308       3         0                       Zimmerman, Mr. Leo    male  29.0   \n",
    "    \n",
    "          sibsp  parch  ticket     fare cabin embarked boat   body home.dest  \n",
    "    1299      1      0    2659  14.4542   NaN        C    C    NaN       NaN  \n",
    "    1300      1      0    2659  14.4542   NaN        C  NaN    NaN       NaN  \n",
    "    1301      0      0    2628   7.2250   NaN        C  NaN  312.0       NaN  \n",
    "    1302      0      0    2647   7.2250   NaN        C  NaN    NaN       NaN  \n",
    "    1303      0      0    2627  14.4583   NaN        C  NaN    NaN       NaN  \n",
    "    1304      1      0    2665  14.4542   NaN        C  NaN  328.0       NaN  \n",
    "    1305      1      0    2665  14.4542   NaN        C  NaN    NaN       NaN  \n",
    "    1306      0      0    2656   7.2250   NaN        C  NaN  304.0       NaN  \n",
    "    1307      0      0    2670   7.2250   NaN        C  NaN    NaN       NaN  \n",
    "    1308      0      0  315082   7.8750   NaN        S  NaN    NaN       NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other transformations with .apply\n",
    "\n",
    "The .apply() method when used on a groupby object performs an arbitrary function on each of the groups. These functions can be aggregations, transformations or more complex workflows. The .apply() method will then combine the results in an intelligent way."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Group gapminder_2010 by 'region': regional\n",
    "regional = gapminder_2010.groupby('region')\n",
    "\n",
    "# Apply the disparity function on regional: reg_disp\n",
    "reg_disp = regional.apply(disparity)\n",
    "\n",
    "# Print the disparity of 'United States', 'United Kingdom', and 'China'\n",
    "print(reg_disp.loc[['United States','United Kingdom','China']])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "                    regional spread(gdp)    z(gdp)\n",
    "    Country                                       \n",
    "    United States                47855.0  3.013374\n",
    "    United Kingdom               89037.0  0.572873\n",
    "    China                        96993.0 -0.432756"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby and filtering\n",
    "\n",
    "### Grouping and filtering with .apply()\n",
    "\n",
    "By using .apply(), you can write functions that filter rows within groups. The .apply() method will handle the iteration over individual groups and then re-combine them back into a Series or DataFrame.\n",
    "\n",
    "def c_deck_survival(gr):\n",
    "\n",
    "    c_passengers = gr['cabin'].str.startswith('C').fillna(False)\n",
    "\n",
    "    return gr.loc[c_passengers, 'survived'].mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a groupby object using titanic over the 'sex' column: by_sex\n",
    "by_sex = titanic.groupby('sex')\n",
    "\n",
    "# Call by_sex.apply with the function c_deck_survival and print the result\n",
    "c_surv_by_sex = by_sex.apply(c_deck_survival)\n",
    "\n",
    "# Print the survival rates\n",
    "print(c_surv_by_sex)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    sex\n",
    "    female    0.913043\n",
    "    male      0.312500\n",
    "    dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and filtering with .filter()\n",
    "\n",
    "You can use groupby with the .filter() method to remove whole groups of rows from a DataFrame based on a boolean condition."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Read the CSV file into a DataFrame: sales\n",
    "sales = pd.read_csv('sales.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Group sales by 'Company': by_company\n",
    "by_company = sales.groupby('Company')\n",
    "\n",
    "# Compute the sum of the 'Units' of by_company: by_com_sum\n",
    "by_com_sum = by_company['Units'].sum()\n",
    "print(by_com_sum)\n",
    "\n",
    "# Filter 'Units' where the sum is > 35: by_com_filt\n",
    "by_com_filt = by_company.filter(lambda g:g['Units'].sum() > 35)\n",
    "print(by_com_filt)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    Company\n",
    "    Acme Coporation    34\n",
    "    Hooli              30\n",
    "    Initech            30\n",
    "    Mediacore          45\n",
    "    Streeplex          36\n",
    "    Name: Units, dtype: int64\n",
    "                           Company   Product  Units\n",
    "    Date                                           \n",
    "    2015-02-02 21:00:00  Mediacore  Hardware      9\n",
    "    2015-02-04 15:30:00  Streeplex  Software     13\n",
    "    2015-02-09 09:00:00  Streeplex   Service     19\n",
    "    2015-02-09 13:00:00  Mediacore  Software      7\n",
    "    2015-02-19 11:00:00  Mediacore  Hardware     16\n",
    "    2015-02-19 16:00:00  Mediacore   Service     10\n",
    "    2015-02-21 05:00:00  Mediacore  Software      3\n",
    "    2015-02-26 09:00:00  Streeplex   Service      4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering and grouping with .map()\n",
    "\n",
    "Sometimes, you may instead want to group by a function/transformation of a column. The key here is that the Series is indexed the same way as the DataFrame. You can also mix and match column grouping with Series grouping."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create the Boolean Series: under10\n",
    "under10 = (titanic['age'] < 10).map({True:'under 10', False:'over 10'})\n",
    "\n",
    "# Group by under10 and compute the survival rate\n",
    "survived_mean_1 = titanic.groupby(under10)['survived'].mean()\n",
    "print(survived_mean_1)\n",
    "\n",
    "# Group by under10 and pclass and compute the survival rate\n",
    "survived_mean_2 = titanic.groupby([under10, 'pclass'])['survived'].mean()\n",
    "print(survived_mean_2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    age\n",
    "    over 10     0.366748\n",
    "    under 10    0.609756\n",
    "    Name: survived, dtype: float64\n",
    "    age       pclass\n",
    "    over 10   1         0.617555\n",
    "              2         0.380392\n",
    "              3         0.238897\n",
    "    under 10  1         0.750000\n",
    "              2         1.000000\n",
    "              3         0.446429\n",
    "    Name: survived, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reminder: indexing & pivoting\n",
    "\n",
    "- Filtering and indexing \n",
    " - One-level indexing\n",
    " - Multi-level indexing\n",
    "- Reshaping DataFrames with pivot() \n",
    "- pivot_table()\n",
    "\n",
    "#### Reminder: groupby\n",
    "- Useful DataFrame methods \n",
    " - unique()\n",
    " - value_counts()\n",
    " - Aggregations, transformations, filtering\n",
    " \n",
    "### Grouping and aggregating\n",
    "\n",
    "USA_edition_grouped['Medal'].count()\n",
    "\n",
    "### Using .value_counts() for ranking\n",
    "\n",
    "Notice that .value_counts() sorts by values by default. The result is returned as a Series of counts indexed by unique entries from the original Series with values (counts) ranked in descending order."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Select the 'NOC' column of medals: country_names\n",
    "country_names = medals['NOC']\n",
    "\n",
    "# Count the number of medals won by each country: medal_counts\n",
    "medal_counts = country_names.value_counts()\n",
    "\n",
    "# Print top 15 countries ranked by medals\n",
    "print(medal_counts.head(15))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    USA    4335\n",
    "    URS    2049\n",
    "    GBR    1594\n",
    "    FRA    1314\n",
    "    ITA    1228\n",
    "    GER    1211\n",
    "    AUS    1075\n",
    "    HUN    1053\n",
    "    SWE    1021\n",
    "    GDR     825\n",
    "    NED     782\n",
    "    JPN     704\n",
    "    CHN     679\n",
    "    RUS     638\n",
    "    ROU     624\n",
    "    Name: NOC, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using .pivot_table() to count medals by type\n",
    "\n",
    "Rather than ranking countries by total medals won and showing that list, you may want to see a bit more detail. You can use a pivot table to compute how many separate bronze, silver and gold medals each country won. That pivot table can then be used to repeat the previous computation to rank by total medals won."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Construct the pivot table: counted\n",
    "counted = medals.pivot_table(index='NOC',columns='Medal',values='Athlete',aggfunc='count')\n",
    "\n",
    "# Create the new column: counted['totals']\n",
    "counted['totals'] = counted.sum(axis='columns')\n",
    "\n",
    "# Sort counted by the 'totals' column\n",
    "counted = counted.sort_values('totals', ascending=False)\n",
    "\n",
    "# Print the top 15 rows of counted\n",
    "print(counted.head(15))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    Medal  Bronze    Gold  Silver  totals\n",
    "    NOC                                  \n",
    "    USA    1052.0  2088.0  1195.0  4335.0\n",
    "    URS     584.0   838.0   627.0  2049.0\n",
    "    GBR     505.0   498.0   591.0  1594.0\n",
    "    FRA     475.0   378.0   461.0  1314.0\n",
    "    ITA     374.0   460.0   394.0  1228.0\n",
    "    GER     454.0   407.0   350.0  1211.0\n",
    "    AUS     413.0   293.0   369.0  1075.0\n",
    "    HUN     345.0   400.0   308.0  1053.0\n",
    "    SWE     325.0   347.0   349.0  1021.0\n",
    "    GDR     225.0   329.0   271.0   825.0\n",
    "    NED     320.0   212.0   250.0   782.0\n",
    "    JPN     270.0   206.0   228.0   704.0\n",
    "    CHN     193.0   234.0   252.0   679.0\n",
    "    RUS     240.0   192.0   206.0   638.0\n",
    "    ROU     282.0   155.0   187.0   624.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the column labels\n",
    "\n",
    "#### Reminder: slicing & filtering\n",
    "- Indexing and slicing\n",
    " - .loc[] and .iloc[] accessors\n",
    "- Filtering\n",
    " - Selecting by Boolean Series\n",
    " - Filtering null/non-null and zero/non-zero values\n",
    "\n",
    "#### Reminder: Handling categorical data\n",
    "- Useful DataFrame methods for handling categorical data: \n",
    " - value_counts()\n",
    " - unique()\n",
    " - groupby()\n",
    "- groupby() aggregations:\n",
    " - mean(), std(), count()\n",
    " \n",
    "### Applying .drop_duplicates()\n",
    "\n",
    "The duplicates can be dropped using the .drop_duplicates() method, leaving behind the unique observations. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Select columns: ev_gen\n",
    "ev_gen = medals.loc[('Event_gender','Gender')]\n",
    "\n",
    "# Drop duplicate pairs: ev_gen_uniques\n",
    "ev_gen_uniques = ev_gen.drop_duplicates()\n",
    "\n",
    "# Print ev_gen_uniques\n",
    "print(ev_gen_uniques)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "          Event_gender Gender\n",
    "    0                M    Men\n",
    "    348              X    Men\n",
    "    416              W  Women\n",
    "    639              X  Women\n",
    "    23675            W    Men"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding possible errors with .groupby()\n",
    "\n",
    "You will now use .groupby() to continue your exploration"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Group medals by the two columns: medals_by_gender\n",
    "medals_by_gender = medals.groupby(['Event_gender','Gender'])\n",
    "\n",
    "# Create a DataFrame with a group count: medal_count_by_gender\n",
    "medal_count_by_gender = medals_by_gender.count()\n",
    "\n",
    "# Print medal_count_by_gender\n",
    "print(medal_count_by_gender)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "                          City  Edition  Sport  Discipline  Athlete    NOC  Event  \\\n",
    "    Event_gender Gender                                                             \n",
    "    M            Men     20067    20067  20067       20067    20067  20067  20067   \n",
    "    W            Men         1        1      1           1        1      1      1   \n",
    "                 Women    7277     7277   7277        7277     7277   7277   7277   \n",
    "    X            Men      1653     1653   1653        1653     1653   1653   1653   \n",
    "                 Women     218      218    218         218      218    218    218   \n",
    "    \n",
    "                         Medal  \n",
    "    Event_gender Gender         \n",
    "    M            Men     20067  \n",
    "    W            Men         1  \n",
    "                 Women    7277  \n",
    "    X            Men      1653  \n",
    "                 Women     218"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locating suspicious data\n",
    "\n",
    "You will now inspect the suspect record by locating the offending row."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create the Boolean Series: sus\n",
    "sus = (medals.Event_gender == 'W') & (medals.Gender == 'Men')\n",
    "\n",
    "# Create a DataFrame with the suspicious row: suspect\n",
    "suspect = pd.DataFrame(medals[sus])\n",
    "\n",
    "# Print suspect\n",
    "print(suspect)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "             City  Edition      Sport Discipline            Athlete  NOC Gender  \\\n",
    "    23675  Sydney     2000  Athletics  Athletics  CHEPCHUMBA, Joyce  KEN    Men   \n",
    "    \n",
    "              Event Event_gender   Medal  \n",
    "    23675  marathon            W  Bronze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing alternative country rankings\n",
    "\n",
    "#### Two new DataFrame methods\n",
    "- idxmax(): Row or column label where maximum value is located\n",
    "- idxmin(): Row or column label where minimum value is located\n",
    "\n",
    "### Using .nunique() to rank by distinct sports\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Group medals by 'NOC': country_grouped\n",
    "country_grouped = medals.groupby('NOC')\n",
    "\n",
    "# Compute the number of distinct sports in which each country won medals: Nsports\n",
    "Nsports = country_grouped['Sport'].nunique()\n",
    "\n",
    "# Sort the values of Nsports in descending order\n",
    "Nsports = Nsports.sort_values(ascending=False)\n",
    "\n",
    "# Print the top 15 rows of Nsports\n",
    "print(Nsports.head(15))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script.py> output:\n",
    "    NOC\n",
    "    USA    34\n",
    "    GBR    31\n",
    "    FRA    28\n",
    "    GER    26\n",
    "    CHN    24\n",
    "    AUS    22\n",
    "    ESP    22\n",
    "    CAN    22\n",
    "    SWE    21\n",
    "    URS    21\n",
    "    ITA    21\n",
    "    NED    20\n",
    "    RUS    20\n",
    "    JPN    20\n",
    "    DEN    19\n",
    "    Name: Sport, dtype: int64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
